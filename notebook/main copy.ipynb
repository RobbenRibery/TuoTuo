{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys \n",
    "if '/Users/ericliu/Desktop/Latent-Dirichilet-Allocation' not in sys.path: \n",
    "    sys.path.append('/Users/ericliu/Desktop/Latent-Dirichilet-Allocation')\n",
    "import torch as tr \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation \n",
    "from src.lda_model import LDASmoothed \n",
    "from src.generator import doc_generator \n",
    "from src.utils import (\n",
    "    get_vocab_from_docs, \n",
    "    get_np_wct, \n",
    "    data_loader,\n",
    "    text_pipeline, \n",
    "    process_documents,\n",
    "    compute_elbo,\n",
    ") \n",
    "from src.text_pre_processor import (\n",
    "    remove_accented_chars, \n",
    "    remove_special_characters, \n",
    "    remove_punctuation,\n",
    "    remove_extra_whitespace_tabs,\n",
    "    remove_stopwords,\n",
    ")\n",
    "from pprint import pprint \n",
    "import copy  \n",
    "\n",
    "from src.cutils import (\n",
    "    _dirichlet_expectation_1d, \n",
    "    _dirichlet_expectation_2d,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = doc_generator(\n",
    "    M = 3,\n",
    "    L = 20, \n",
    "    topic_prior = tr.tensor([1,1,1,1,1], dtype=tr.double)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1131, 0.0589, 0.0824, 0.1060, 0.0471, 0.0824, 0.0294, 0.1060, 0.0059,\n",
       "         0.0047, 0.0353, 0.0059, 0.0118, 0.0035, 0.0012, 0.0012, 0.0118, 0.0118,\n",
       "         0.0236, 0.0236, 0.0177, 0.0177, 0.0041, 0.0047, 0.0353, 0.0059, 0.0118,\n",
       "         0.0353, 0.0177, 0.0118, 0.0029, 0.0035, 0.0029, 0.0012, 0.0353, 0.0029,\n",
       "         0.0059, 0.0118, 0.0029, 0.0029],\n",
       "        [0.0012, 0.0047, 0.0047, 0.0030, 0.0355, 0.0118, 0.0237, 0.0030, 0.0948,\n",
       "         0.0592, 0.0592, 0.1066, 0.0474, 0.1066, 0.0948, 0.1126, 0.0237, 0.0059,\n",
       "         0.0059, 0.0118, 0.0178, 0.0178, 0.0041, 0.0047, 0.0047, 0.0237, 0.0118,\n",
       "         0.0296, 0.0059, 0.0237, 0.0030, 0.0036, 0.0030, 0.0012, 0.0036, 0.0030,\n",
       "         0.0047, 0.0118, 0.0030, 0.0030],\n",
       "        [0.0014, 0.0057, 0.0043, 0.0036, 0.0143, 0.0071, 0.0286, 0.0036, 0.0071,\n",
       "         0.0043, 0.0214, 0.0014, 0.0428, 0.0043, 0.0143, 0.0014, 0.0500, 0.0999,\n",
       "         0.0999, 0.0571, 0.0857, 0.0857, 0.1285, 0.1285, 0.0057, 0.0014, 0.0143,\n",
       "         0.0071, 0.0071, 0.0071, 0.0036, 0.0143, 0.0036, 0.0014, 0.0043, 0.0036,\n",
       "         0.0043, 0.0143, 0.0036, 0.0036],\n",
       "        [0.0013, 0.0507, 0.0253, 0.0032, 0.0127, 0.0127, 0.0317, 0.0032, 0.0063,\n",
       "         0.0507, 0.0032, 0.0013, 0.0127, 0.0025, 0.0051, 0.0013, 0.0253, 0.0063,\n",
       "         0.0032, 0.0127, 0.0190, 0.0190, 0.0019, 0.0013, 0.0760, 0.0887, 0.0633,\n",
       "         0.0443, 0.0887, 0.0760, 0.1140, 0.1013, 0.0032, 0.0013, 0.0051, 0.0032,\n",
       "         0.0038, 0.0127, 0.0032, 0.0032],\n",
       "        [0.0012, 0.0023, 0.0035, 0.0029, 0.0117, 0.0058, 0.0117, 0.0029, 0.0058,\n",
       "         0.0035, 0.0029, 0.0035, 0.0117, 0.0023, 0.0047, 0.0023, 0.0175, 0.0117,\n",
       "         0.0029, 0.0234, 0.0175, 0.0175, 0.0018, 0.0012, 0.0023, 0.0047, 0.0234,\n",
       "         0.0058, 0.0058, 0.0058, 0.0029, 0.0047, 0.1051, 0.1121, 0.0701, 0.1051,\n",
       "         0.0993, 0.0701, 0.1051, 0.1051]], dtype=torch.float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dirichlet(concentration: torch.Size([5]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0015, 0.3438, 0.5711, 0.0634, 0.0203],\n",
       "        [0.2904, 0.1069, 0.0383, 0.2283, 0.3362],\n",
       "        [0.2239, 0.0208, 0.2862, 0.1523, 0.3168]], dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: 0 | word: 0 -> topic: sport -> word: exercise\n",
      "Document: 0 | word: 1 -> topic: law -> word: contract\n",
      "Document: 0 | word: 2 -> topic: art -> word: concert\n",
      "Document: 0 | word: 3 -> topic: sport -> word: Olympic\n",
      "Document: 0 | word: 4 -> topic: art -> word: form\n",
      "Document: 0 | word: 5 -> topic: law -> word: divorce\n",
      "Document: 0 | word: 6 -> topic: art -> word: Craftsmanship\n",
      "Document: 0 | word: 7 -> topic: art -> word: concert\n",
      "Document: 0 | word: 8 -> topic: art -> word: concert\n",
      "Document: 0 | word: 9 -> topic: art -> word: electricity\n",
      "Document 0: exercise contract concert Olympic form divorce Craftsmanship concert concert electricity\n",
      "\n",
      "Document: 1 | word: 0 -> topic: law -> word: court\n",
      "Document: 1 | word: 1 -> topic: law -> word: court\n",
      "Document: 1 | word: 2 -> topic: health -> word: immunology\n",
      "Document: 1 | word: 3 -> topic: science -> word: electricity\n",
      "Document: 1 | word: 4 -> topic: law -> word: bankrupt\n",
      "Document: 1 | word: 5 -> topic: law -> word: accuse\n",
      "Document: 1 | word: 6 -> topic: science -> word: quantum\n",
      "Document: 1 | word: 7 -> topic: law -> word: electricity\n",
      "Document: 1 | word: 8 -> topic: law -> word: divorce\n",
      "Document: 1 | word: 9 -> topic: health -> word: decongestant\n",
      "Document 1: court court immunology electricity bankrupt accuse quantum electricity divorce decongestant\n",
      "\n",
      "Document: 2 | word: 0 -> topic: art -> word: asymmetrical\n",
      "Document: 2 | word: 1 -> topic: science -> word: astrophysics\n",
      "Document: 2 | word: 2 -> topic: art -> word: immunology\n",
      "Document: 2 | word: 3 -> topic: law -> word: attorney\n",
      "Document: 2 | word: 4 -> topic: art -> word: picture\n",
      "Document: 2 | word: 5 -> topic: law -> word: attorney\n",
      "Document: 2 | word: 6 -> topic: health -> word: appetite\n",
      "Document: 2 | word: 7 -> topic: law -> word: court\n",
      "Document: 2 | word: 8 -> topic: health -> word: decongestant\n",
      "Document: 2 | word: 9 -> topic: health -> word: immunology\n",
      "Document 2: asymmetrical astrophysics immunology attorney picture attorney appetite court decongestant immunology\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = gen.generate_doc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'exercise contract concert Olympic form divorce Craftsmanship concert concert electricity',\n",
       " 1: 'court court immunology electricity bankrupt accuse quantum electricity divorce decongestant',\n",
       " 2: 'asymmetrical astrophysics immunology attorney picture attorney appetite court decongestant immunology'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs_raw_dict, raw_word_2_idx, raw_idx_2_word = data_loader('ap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 documents in the dataset after processing\n",
      "On average estimated document length is 10.0 words per document after processing\n",
      "There are 19 unique vocab in the corpus after processing\n"
     ]
    }
   ],
   "source": [
    "result = process_documents(docs, sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['documents', 'vocab_doc_count_dict', 'vocab_doc_count_array', 'vocab_to_idx', 'idx_to_vocab'])\n"
     ]
    }
   ],
   "source": [
    "print(result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['exercise',\n",
       "  'contract',\n",
       "  'concert',\n",
       "  'Olympic',\n",
       "  'form',\n",
       "  'divorce',\n",
       "  'Craftsmanship',\n",
       "  'concert',\n",
       "  'concert',\n",
       "  'electricity'],\n",
       " ['court',\n",
       "  'court',\n",
       "  'immunology',\n",
       "  'electricity',\n",
       "  'bankrupt',\n",
       "  'accuse',\n",
       "  'quantum',\n",
       "  'electricity',\n",
       "  'divorce',\n",
       "  'decongestant'],\n",
       " ['asymmetrical',\n",
       "  'astrophysics',\n",
       "  'immunology',\n",
       "  'attorney',\n",
       "  'picture',\n",
       "  'attorney',\n",
       "  'appetite',\n",
       "  'court',\n",
       "  'decongestant',\n",
       "  'immunology']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exercise': 0,\n",
       " 'contract': 1,\n",
       " 'concert': 2,\n",
       " 'Olympic': 3,\n",
       " 'form': 4,\n",
       " 'divorce': 5,\n",
       " 'Craftsmanship': 6,\n",
       " 'electricity': 7,\n",
       " 'court': 8,\n",
       " 'immunology': 9,\n",
       " 'bankrupt': 10,\n",
       " 'accuse': 11,\n",
       " 'quantum': 12,\n",
       " 'decongestant': 13,\n",
       " 'asymmetrical': 14,\n",
       " 'astrophysics': 15,\n",
       " 'attorney': 16,\n",
       " 'picture': 17,\n",
       " 'appetite': 18}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['vocab_to_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 3., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 2., 2., 1., 1., 1., 1., 1., 0., 0.,\n",
       "        0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 2., 0., 0., 0., 1., 1., 1.,\n",
       "        2., 1., 1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vocab_count = np.zeros(\n",
    "    (\n",
    "        len(docs), len(result['vocab_to_idx'])\n",
    "    ),\n",
    "    dtype = float,\n",
    ")\n",
    "\n",
    "for doc_idx, doc in enumerate(result['documents']): \n",
    "\n",
    "    for word in doc: \n",
    "\n",
    "        vocab_idx = result['vocab_to_idx'][word]\n",
    "        doc_vocab_count[doc_idx, vocab_idx] += 1 \n",
    "\n",
    "doc_vocab_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exercise</th>\n",
       "      <th>contract</th>\n",
       "      <th>concert</th>\n",
       "      <th>Olympic</th>\n",
       "      <th>form</th>\n",
       "      <th>divorce</th>\n",
       "      <th>Craftsmanship</th>\n",
       "      <th>electricity</th>\n",
       "      <th>court</th>\n",
       "      <th>immunology</th>\n",
       "      <th>bankrupt</th>\n",
       "      <th>accuse</th>\n",
       "      <th>quantum</th>\n",
       "      <th>decongestant</th>\n",
       "      <th>asymmetrical</th>\n",
       "      <th>astrophysics</th>\n",
       "      <th>attorney</th>\n",
       "      <th>picture</th>\n",
       "      <th>appetite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   exercise  contract  concert  Olympic  form  divorce  Craftsmanship  \\\n",
       "0       1.0       1.0      3.0      1.0   1.0      1.0            1.0   \n",
       "1       0.0       0.0      0.0      0.0   0.0      1.0            0.0   \n",
       "2       0.0       0.0      0.0      0.0   0.0      0.0            0.0   \n",
       "\n",
       "   electricity  court  immunology  bankrupt  accuse  quantum  decongestant  \\\n",
       "0          1.0    0.0         0.0       0.0     0.0      0.0           0.0   \n",
       "1          2.0    2.0         1.0       1.0     1.0      1.0           1.0   \n",
       "2          0.0    1.0         2.0       0.0     0.0      0.0           1.0   \n",
       "\n",
       "   asymmetrical  astrophysics  attorney  picture  appetite  \n",
       "0           0.0           0.0       0.0      0.0       0.0  \n",
       "1           0.0           0.0       0.0      0.0       0.0  \n",
       "2           1.0           1.0       2.0      1.0       1.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vocab_count_df = pd.DataFrame(\n",
    "    data = doc_vocab_count,\n",
    "    columns = list(result['vocab_to_idx'].keys())\n",
    ")\n",
    "doc_vocab_count_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic Dirichlet Prior, Alpha\n",
      "1\n",
      "\n",
      "Exchangeable Word Dirichlet Prior, Eta \n",
      "1\n",
      "\n",
      "Var Inf - Word Dirichlet prior, Lambda\n",
      "(5, 19)\n",
      "\n",
      "Var Inf - Topic Dirichlet prior, Gamma\n",
      "(3, 5)\n",
      "\n",
      "loop phi\n",
      "looped\n",
      "double\n",
      "Var -Inf - Word wise Topic Multinomial/Categorical, Phi\n",
      "(3, 19, 5)\n",
      "Size of the vocab is 19\n"
     ]
    }
   ],
   "source": [
    "lda = LDASmoothed(\n",
    "    docs = result['documents'],\n",
    "    num_topics = 5, \n",
    "    word_ct_dict = result['vocab_doc_count_dict'], \n",
    "    num_doc_population = 3,\n",
    "    word_ct_array = result['vocab_doc_count_array'],\n",
    ")\n",
    "print(f'Size of the vocab is {lda.V}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-113.91027683348449"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.approx_elbo(\n",
    "    doc_vocab_count,\n",
    "    sampling=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(lda._alpha_)\n",
    "print(lda._eta_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check var inf parameteres "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda\n",
      "(5, 19)\n",
      "[[1.04708219 0.98292693 0.97347267 0.97347428 1.16278368 1.07526208\n",
      "  0.95052839 1.05181933 1.02101821 0.81760009 0.89893338 1.0283693\n",
      "  1.15026429 0.97429619 0.94330106 1.00778149 0.9378975  0.96782864\n",
      "  0.9953198 ]\n",
      " [0.89475728 1.08105987 0.87968664 0.86986295 1.01644942 1.07222286\n",
      "  1.01387299 0.98516565 0.96690772 0.95138329 1.10597141 1.02937237\n",
      "  0.95871485 0.93060329 1.05898791 1.1031785  1.09256024 0.91521059\n",
      "  0.96611462]\n",
      " [0.94959045 0.9782464  1.08000428 1.13828828 1.03320764 0.93363961\n",
      "  0.99309432 1.16117251 1.00538214 0.96711283 0.97489658 1.03274514\n",
      "  0.91811143 0.94740917 1.09087585 1.02984852 1.00638968 1.09653088\n",
      "  0.92820856]\n",
      " [0.96431168 1.02652255 1.02295647 0.86193808 0.95525935 0.98065155\n",
      "  1.03755099 1.02260049 0.98925295 0.81711981 0.99402204 1.00269174\n",
      "  1.26335968 0.97758574 1.02707522 1.11516717 1.07363499 1.14337395\n",
      "  0.86316381]\n",
      " [0.90101275 0.9411936  0.84973584 1.00352721 0.90766658 1.15954736\n",
      "  0.92049911 0.96485874 1.0801087  0.87876646 0.84464572 1.01521312\n",
      "  1.02283738 1.07677376 1.04968711 1.02661057 0.93030741 1.02003357\n",
      "  1.02621227]]\n"
     ]
    }
   ],
   "source": [
    "print('lambda')\n",
    "print(lda._lambda_.shape)\n",
    "print(lda._lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma\n",
      "[[4.8 4.8 4.8 4.8 4.8]\n",
      " [4.8 4.8 4.8 4.8 4.8]\n",
      " [4.8 4.8 4.8 4.8 4.8]]\n"
     ]
    }
   ],
   "source": [
    "print('gamma')\n",
    "print(lda._gamma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi\n",
      "[[[0.2 0.2 0.2 0.2 0.2]\n",
      "  [0.2 0.2 0.2 0.2 0.2]\n",
      "  [0.2 0.2 0.2 0.2 0.2]\n",
      "  [0.2 0.2 0.2 0.2 0.2]\n",
      "  [0.2 0.2 0.2 0.2 0.2]\n",
      "  [0.2 0.2 0.2 0.2 0.2]\n",
      "  [0.2 0.2 0.2 0.2 0.2]\n",
      "  [0.2 0.2 0.2 0.2 0.2]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]]\n",
      "\n",
      " [[0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.2 0.2 0.2 0.2 0.2]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.2 0.2 0.2 0.2 0.2]\n",
      "  [0.2 0.2 0.2 0.2 0.2]\n",
      "  [0.2 0.2 0.2 0.2 0.2]\n",
      "  [0.2 0.2 0.2 0.2 0.2]\n",
      "  [0.2 0.2 0.2 0.2 0.2]\n",
      "  [0.2 0.2 0.2 0.2 0.2]\n",
      "  [0.2 0.2 0.2 0.2 0.2]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]]\n",
      "\n",
      " [[0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.2 0.2 0.2 0.2 0.2]\n",
      "  [0.2 0.2 0.2 0.2 0.2]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0. ]\n",
      "  [0.2 0.2 0.2 0.2 0.2]\n",
      "  [0.2 0.2 0.2 0.2 0.2]\n",
      "  [0.2 0.2 0.2 0.2 0.2]\n",
      "  [0.2 0.2 0.2 0.2 0.2]\n",
      "  [0.2 0.2 0.2 0.2 0.2]\n",
      "  [0.2 0.2 0.2 0.2 0.2]]]\n"
     ]
    }
   ],
   "source": [
    "print('phi')\n",
    "print(lda._phi_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_lda = LatentDirichletAllocation(\n",
    "    n_components=5,\n",
    "    random_state=42,\n",
    "    doc_topic_prior= 1,\n",
    "    topic_word_prior= 1,\n",
    ")\n",
    "sklearn_lda._init_latent_vars(n_features = lda.V)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha -> 1\n",
      "eta -> 1\n"
     ]
    }
   ],
   "source": [
    "# alpha \n",
    "print(f\"alpha -> {sklearn_lda.doc_topic_prior}\")\n",
    "print(f\"eta -> {sklearn_lda.topic_word_prior}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- var inf parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda\n",
      "[[1.04708219 0.98292693 0.97347267 0.97347428 1.16278368 1.07526208\n",
      "  0.95052839 1.05181933 1.02101821 0.81760009 0.89893338 1.0283693\n",
      "  1.15026429 0.97429619 0.94330106 1.00778149 0.9378975  0.96782864\n",
      "  0.9953198 ]\n",
      " [0.89475728 1.08105987 0.87968664 0.86986295 1.01644942 1.07222286\n",
      "  1.01387299 0.98516565 0.96690772 0.95138329 1.10597141 1.02937237\n",
      "  0.95871485 0.93060329 1.05898791 1.1031785  1.09256024 0.91521059\n",
      "  0.96611462]\n",
      " [0.94959045 0.9782464  1.08000428 1.13828828 1.03320764 0.93363961\n",
      "  0.99309432 1.16117251 1.00538214 0.96711283 0.97489658 1.03274514\n",
      "  0.91811143 0.94740917 1.09087585 1.02984852 1.00638968 1.09653088\n",
      "  0.92820856]\n",
      " [0.96431168 1.02652255 1.02295647 0.86193808 0.95525935 0.98065155\n",
      "  1.03755099 1.02260049 0.98925295 0.81711981 0.99402204 1.00269174\n",
      "  1.26335968 0.97758574 1.02707522 1.11516717 1.07363499 1.14337395\n",
      "  0.86316381]\n",
      " [0.90101275 0.9411936  0.84973584 1.00352721 0.90766658 1.15954736\n",
      "  0.92049911 0.96485874 1.0801087  0.87876646 0.84464572 1.01521312\n",
      "  1.02283738 1.07677376 1.04968711 1.02661057 0.93030741 1.02003357\n",
      "  1.02621227]]\n"
     ]
    }
   ],
   "source": [
    "print('lambda')\n",
    "print(sklearn_lda.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (sklearn_lda.components_ == lda._lambda_).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-113.71880962020522"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_lda._approx_bound(\n",
    "    doc_vocab_count,\n",
    "    doc_topic_distr = lda._gamma_,\n",
    "    sub_sampling = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
