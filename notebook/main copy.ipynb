{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys \n",
    "if '/Users/ericliu/Desktop/Latent-Dirichilet-Allocation' not in sys.path: \n",
    "    sys.path.append('/Users/ericliu/Desktop/Latent-Dirichilet-Allocation')\n",
    "import torch as tr \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation \n",
    "from src.lda_model import LDASmoothed \n",
    "from src.generator import doc_generator \n",
    "from src.utils import (\n",
    "    get_vocab_from_docs, \n",
    "    get_np_wct, \n",
    "    data_loader,\n",
    "    text_pipeline, \n",
    "    process_documents,\n",
    "    compute_elbo,\n",
    ") \n",
    "from src.text_pre_processor import (\n",
    "    remove_accented_chars, \n",
    "    remove_special_characters, \n",
    "    remove_punctuation,\n",
    "    remove_extra_whitespace_tabs,\n",
    "    remove_stopwords,\n",
    ")\n",
    "from pprint import pprint \n",
    "import copy  \n",
    "\n",
    "from src.cutils import (\n",
    "    _dirichlet_expectation_1d, \n",
    "    _dirichlet_expectation_2d,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = doc_generator(\n",
    "    M = 5,\n",
    "    L = 20, \n",
    "    topic_prior = tr.tensor([1,1,1,1,1], dtype=tr.double)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1131, 0.0589, 0.0824, 0.1060, 0.0471, 0.0824, 0.0294, 0.1060, 0.0059,\n",
       "         0.0047, 0.0353, 0.0059, 0.0118, 0.0035, 0.0012, 0.0012, 0.0118, 0.0118,\n",
       "         0.0236, 0.0236, 0.0177, 0.0177, 0.0041, 0.0047, 0.0353, 0.0059, 0.0118,\n",
       "         0.0353, 0.0177, 0.0118, 0.0029, 0.0035, 0.0029, 0.0012, 0.0353, 0.0029,\n",
       "         0.0059, 0.0118, 0.0029, 0.0029],\n",
       "        [0.0012, 0.0047, 0.0047, 0.0030, 0.0355, 0.0118, 0.0237, 0.0030, 0.0948,\n",
       "         0.0592, 0.0592, 0.1066, 0.0474, 0.1066, 0.0948, 0.1126, 0.0237, 0.0059,\n",
       "         0.0059, 0.0118, 0.0178, 0.0178, 0.0041, 0.0047, 0.0047, 0.0237, 0.0118,\n",
       "         0.0296, 0.0059, 0.0237, 0.0030, 0.0036, 0.0030, 0.0012, 0.0036, 0.0030,\n",
       "         0.0047, 0.0118, 0.0030, 0.0030],\n",
       "        [0.0014, 0.0057, 0.0043, 0.0036, 0.0143, 0.0071, 0.0286, 0.0036, 0.0071,\n",
       "         0.0043, 0.0214, 0.0014, 0.0428, 0.0043, 0.0143, 0.0014, 0.0500, 0.0999,\n",
       "         0.0999, 0.0571, 0.0857, 0.0857, 0.1285, 0.1285, 0.0057, 0.0014, 0.0143,\n",
       "         0.0071, 0.0071, 0.0071, 0.0036, 0.0143, 0.0036, 0.0014, 0.0043, 0.0036,\n",
       "         0.0043, 0.0143, 0.0036, 0.0036],\n",
       "        [0.0013, 0.0507, 0.0253, 0.0032, 0.0127, 0.0127, 0.0317, 0.0032, 0.0063,\n",
       "         0.0507, 0.0032, 0.0013, 0.0127, 0.0025, 0.0051, 0.0013, 0.0253, 0.0063,\n",
       "         0.0032, 0.0127, 0.0190, 0.0190, 0.0019, 0.0013, 0.0760, 0.0887, 0.0633,\n",
       "         0.0443, 0.0887, 0.0760, 0.1140, 0.1013, 0.0032, 0.0013, 0.0051, 0.0032,\n",
       "         0.0038, 0.0127, 0.0032, 0.0032],\n",
       "        [0.0012, 0.0023, 0.0035, 0.0029, 0.0117, 0.0058, 0.0117, 0.0029, 0.0058,\n",
       "         0.0035, 0.0029, 0.0035, 0.0117, 0.0023, 0.0047, 0.0023, 0.0175, 0.0117,\n",
       "         0.0029, 0.0234, 0.0175, 0.0175, 0.0018, 0.0012, 0.0023, 0.0047, 0.0234,\n",
       "         0.0058, 0.0058, 0.0058, 0.0029, 0.0047, 0.1051, 0.1121, 0.0701, 0.1051,\n",
       "         0.0993, 0.0701, 0.1051, 0.1051]], dtype=torch.float64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dirichlet(concentration: torch.Size([5]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0446, 0.2003, 0.4756, 0.0900, 0.1896],\n",
       "        [0.0206, 0.3647, 0.1089, 0.0235, 0.4823],\n",
       "        [0.5233, 0.0665, 0.0771, 0.1263, 0.2068],\n",
       "        [0.0402, 0.2183, 0.1981, 0.4762, 0.0672],\n",
       "        [0.2672, 0.0198, 0.4494, 0.0683, 0.1953]], dtype=torch.float64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: 0 | word: 0 -> topic: art -> word: Technique\n",
      "Document: 0 | word: 1 -> topic: art -> word: Symmetrical\n",
      "Document: 0 | word: 2 -> topic: sport -> word: FIFA\n",
      "Document: 0 | word: 3 -> topic: art -> word: Craftsmanship\n",
      "Document: 0 | word: 4 -> topic: sport -> word: research\n",
      "Document: 0 | word: 5 -> topic: art -> word: game\n",
      "Document: 0 | word: 6 -> topic: sport -> word: recreation\n",
      "Document: 0 | word: 7 -> topic: law -> word: attorney\n",
      "Document: 0 | word: 8 -> topic: law -> word: accuse\n",
      "Document: 0 | word: 9 -> topic: law -> word: contract\n",
      "Document 0: Technique Symmetrical FIFA Craftsmanship research game recreation attorney accuse contract\n",
      "\n",
      "Document: 1 | word: 0 -> topic: law -> word: divorce\n",
      "Document: 1 | word: 1 -> topic: sport -> word: physical\n",
      "Document: 1 | word: 2 -> topic: law -> word: court\n",
      "Document: 1 | word: 3 -> topic: law -> word: accuse\n",
      "Document: 1 | word: 4 -> topic: art -> word: concert\n",
      "Document: 1 | word: 5 -> topic: law -> word: attorney\n",
      "Document: 1 | word: 6 -> topic: sport -> word: football\n",
      "Document: 1 | word: 7 -> topic: law -> word: divorce\n",
      "Document: 1 | word: 8 -> topic: health -> word: contagious\n",
      "Document: 1 | word: 9 -> topic: law -> word: court\n",
      "Document 1: divorce physical court accuse concert attorney football divorce contagious court\n",
      "\n",
      "Document: 2 | word: 0 -> topic: health -> word: contagious\n",
      "Document: 2 | word: 1 -> topic: science -> word: scientst\n",
      "Document: 2 | word: 2 -> topic: science -> word: scientst\n",
      "Document: 2 | word: 3 -> topic: law -> word: divorce\n",
      "Document: 2 | word: 4 -> topic: science -> word: scientst\n",
      "Document: 2 | word: 5 -> topic: art -> word: concert\n",
      "Document: 2 | word: 6 -> topic: science -> word: contract\n",
      "Document: 2 | word: 7 -> topic: science -> word: electricity\n",
      "Document: 2 | word: 8 -> topic: science -> word: scientst\n",
      "Document: 2 | word: 9 -> topic: law -> word: court\n",
      "Document 2: contagious scientst scientst divorce scientst concert contract electricity scientst court\n",
      "\n",
      "Document: 3 | word: 0 -> topic: law -> word: attorney\n",
      "Document: 3 | word: 1 -> topic: health -> word: decongestant\n",
      "Document: 3 | word: 2 -> topic: art -> word: form\n",
      "Document: 3 | word: 3 -> topic: health -> word: athletics\n",
      "Document: 3 | word: 4 -> topic: sport -> word: FIFA\n",
      "Document: 3 | word: 5 -> topic: sport -> word: athletics\n",
      "Document: 3 | word: 6 -> topic: health -> word: decongestant\n",
      "Document: 3 | word: 7 -> topic: health -> word: game\n",
      "Document: 3 | word: 8 -> topic: health -> word: bruise\n",
      "Document: 3 | word: 9 -> topic: art -> word: injection\n",
      "Document 3: attorney decongestant form athletics FIFA athletics decongestant game bruise injection\n",
      "\n",
      "Document: 4 | word: 0 -> topic: art -> word: electricity\n",
      "Document: 4 | word: 1 -> topic: art -> word: concert\n",
      "Document: 4 | word: 2 -> topic: law -> word: Technique\n",
      "Document: 4 | word: 3 -> topic: science -> word: game\n",
      "Document: 4 | word: 4 -> topic: art -> word: Craftsmanship\n",
      "Document: 4 | word: 5 -> topic: science -> word: asymmetrical\n",
      "Document: 4 | word: 6 -> topic: art -> word: fever\n",
      "Document: 4 | word: 7 -> topic: art -> word: Craftsmanship\n",
      "Document: 4 | word: 8 -> topic: art -> word: asymmetrical\n",
      "Document: 4 | word: 9 -> topic: law -> word: contract\n",
      "Document 4: electricity concert Technique game Craftsmanship asymmetrical fever Craftsmanship asymmetrical contract\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = gen.generate_doc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Technique Symmetrical FIFA Craftsmanship research game recreation attorney accuse contract',\n",
       " 1: 'divorce physical court accuse concert attorney football divorce contagious court',\n",
       " 2: 'contagious scientst scientst divorce scientst concert contract electricity scientst court',\n",
       " 3: 'attorney decongestant form athletics FIFA athletics decongestant game bruise injection',\n",
       " 4: 'electricity concert Technique game Craftsmanship asymmetrical fever Craftsmanship asymmetrical contract'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs_raw_dict, raw_word_2_idx, raw_idx_2_word = data_loader('ap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 documents in the dataset after processing\n",
      "On average estimated document length is 10.0 words per document after processing\n",
      "There are 25 unique vocab in the corpus after processing\n"
     ]
    }
   ],
   "source": [
    "result = process_documents(docs, sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['documents', 'vocab_doc_count_dict', 'vocab_doc_count_array', 'vocab_to_idx', 'idx_to_vocab'])\n"
     ]
    }
   ],
   "source": [
    "print(result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Technique',\n",
       "  'Symmetrical',\n",
       "  'FIFA',\n",
       "  'Craftsmanship',\n",
       "  'research',\n",
       "  'game',\n",
       "  'recreation',\n",
       "  'attorney',\n",
       "  'accuse',\n",
       "  'contract'],\n",
       " ['divorce',\n",
       "  'physical',\n",
       "  'court',\n",
       "  'accuse',\n",
       "  'concert',\n",
       "  'attorney',\n",
       "  'football',\n",
       "  'divorce',\n",
       "  'contagious',\n",
       "  'court'],\n",
       " ['contagious',\n",
       "  'scientst',\n",
       "  'scientst',\n",
       "  'divorce',\n",
       "  'scientst',\n",
       "  'concert',\n",
       "  'contract',\n",
       "  'electricity',\n",
       "  'scientst',\n",
       "  'court'],\n",
       " ['attorney',\n",
       "  'decongestant',\n",
       "  'form',\n",
       "  'athletics',\n",
       "  'FIFA',\n",
       "  'athletics',\n",
       "  'decongestant',\n",
       "  'game',\n",
       "  'bruise',\n",
       "  'injection'],\n",
       " ['electricity',\n",
       "  'concert',\n",
       "  'Technique',\n",
       "  'game',\n",
       "  'Craftsmanship',\n",
       "  'asymmetrical',\n",
       "  'fever',\n",
       "  'Craftsmanship',\n",
       "  'asymmetrical',\n",
       "  'contract']]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Technique': 0,\n",
       " 'Symmetrical': 1,\n",
       " 'FIFA': 2,\n",
       " 'Craftsmanship': 3,\n",
       " 'research': 4,\n",
       " 'game': 5,\n",
       " 'recreation': 6,\n",
       " 'attorney': 7,\n",
       " 'accuse': 8,\n",
       " 'contract': 9,\n",
       " 'divorce': 10,\n",
       " 'physical': 11,\n",
       " 'court': 12,\n",
       " 'concert': 13,\n",
       " 'football': 14,\n",
       " 'contagious': 15,\n",
       " 'scientst': 16,\n",
       " 'electricity': 17,\n",
       " 'decongestant': 18,\n",
       " 'form': 19,\n",
       " 'athletics': 20,\n",
       " 'bruise': 21,\n",
       " 'injection': 22,\n",
       " 'asymmetrical': 23,\n",
       " 'fever': 24}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['vocab_to_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 2., 1., 2., 1., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "        4., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 2., 1., 2., 1., 1., 0., 0.],\n",
       "       [1., 0., 0., 2., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 2., 1.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vocab_count = np.zeros(\n",
    "    (\n",
    "        len(docs), len(result['vocab_to_idx'])\n",
    "    ),\n",
    "    dtype = float,\n",
    ")\n",
    "\n",
    "for doc_idx, doc in enumerate(result['documents']): \n",
    "\n",
    "    for word in doc: \n",
    "\n",
    "        vocab_idx = result['vocab_to_idx'][word]\n",
    "        doc_vocab_count[doc_idx, vocab_idx] += 1 \n",
    "\n",
    "doc_vocab_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Technique</th>\n",
       "      <th>Symmetrical</th>\n",
       "      <th>FIFA</th>\n",
       "      <th>Craftsmanship</th>\n",
       "      <th>research</th>\n",
       "      <th>game</th>\n",
       "      <th>recreation</th>\n",
       "      <th>attorney</th>\n",
       "      <th>accuse</th>\n",
       "      <th>contract</th>\n",
       "      <th>...</th>\n",
       "      <th>contagious</th>\n",
       "      <th>scientst</th>\n",
       "      <th>electricity</th>\n",
       "      <th>decongestant</th>\n",
       "      <th>form</th>\n",
       "      <th>athletics</th>\n",
       "      <th>bruise</th>\n",
       "      <th>injection</th>\n",
       "      <th>asymmetrical</th>\n",
       "      <th>fever</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Technique  Symmetrical  FIFA  Craftsmanship  research  game  recreation  \\\n",
       "0        1.0          1.0   1.0            1.0       1.0   1.0         1.0   \n",
       "1        0.0          0.0   0.0            0.0       0.0   0.0         0.0   \n",
       "2        0.0          0.0   0.0            0.0       0.0   0.0         0.0   \n",
       "3        0.0          0.0   1.0            0.0       0.0   1.0         0.0   \n",
       "4        1.0          0.0   0.0            2.0       0.0   1.0         0.0   \n",
       "\n",
       "   attorney  accuse  contract  ...  contagious  scientst  electricity  \\\n",
       "0       1.0     1.0       1.0  ...         0.0       0.0          0.0   \n",
       "1       1.0     1.0       0.0  ...         1.0       0.0          0.0   \n",
       "2       0.0     0.0       1.0  ...         1.0       4.0          1.0   \n",
       "3       1.0     0.0       0.0  ...         0.0       0.0          0.0   \n",
       "4       0.0     0.0       1.0  ...         0.0       0.0          1.0   \n",
       "\n",
       "   decongestant  form  athletics  bruise  injection  asymmetrical  fever  \n",
       "0           0.0   0.0        0.0     0.0        0.0           0.0    0.0  \n",
       "1           0.0   0.0        0.0     0.0        0.0           0.0    0.0  \n",
       "2           0.0   0.0        0.0     0.0        0.0           0.0    0.0  \n",
       "3           2.0   1.0        2.0     1.0        1.0           0.0    0.0  \n",
       "4           0.0   0.0        0.0     0.0        0.0           2.0    1.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vocab_count_df = pd.DataFrame(\n",
    "    data = doc_vocab_count,\n",
    "    columns = list(result['vocab_to_idx'].keys())\n",
    ")\n",
    "doc_vocab_count_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic Dirichlet Prior, Alpha\n",
      "1\n",
      "\n",
      "Exchangeable Word Dirichlet Prior, Eta \n",
      "1\n",
      "\n",
      "Var Inf - Word Dirichlet prior, Lambda\n",
      "(5, 25)\n",
      "\n",
      "Var Inf - Topic Dirichlet prior, Gamma\n",
      "(5, 5)\n",
      "\n",
      "Size of the vocab is 25\n"
     ]
    }
   ],
   "source": [
    "lda = LDASmoothed(\n",
    "    docs = result['documents'],\n",
    "    num_topics = 5, \n",
    "    word_ct_dict = result['vocab_doc_count_dict'], \n",
    "    num_doc_population = 3,\n",
    "    word_ct_array = result['vocab_doc_count_array'],\n",
    ")\n",
    "print(f'Size of the vocab is {lda.V}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-204.37721599278194\n",
      "59.593369617582205\n",
      "CPU times: user 954 µs, sys: 211 µs, total: 1.16 ms\n",
      "Wall time: 988 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "perplexity, suff_stats = \\\n",
    "    lda.approx_perplexity(\n",
    "    doc_vocab_count,\n",
    "    sampling=False,\n",
    ")\n",
    "\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "expec_log_theta, expect_log_beta = suff_stats[0], suff_stats[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(lda._alpha_)\n",
    "print(lda._eta_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check var inf parameteres "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda\n",
      "(5, 25)\n",
      "[[1.04708219 0.98292693 0.97347267 0.97347428 1.16278368 1.07526208\n",
      "  0.95052839 1.05181933 1.02101821 0.81760009 0.89893338 1.0283693\n",
      "  1.15026429 0.97429619 0.94330106 1.00778149 0.9378975  0.96782864\n",
      "  0.9953198  0.89475728 1.08105987 0.87968664 0.86986295 1.01644942\n",
      "  1.07222286]\n",
      " [1.01387299 0.98516565 0.96690772 0.95138329 1.10597141 1.02937237\n",
      "  0.95871485 0.93060329 1.05898791 1.1031785  1.09256024 0.91521059\n",
      "  0.96611462 0.94959045 0.9782464  1.08000428 1.13828828 1.03320764\n",
      "  0.93363961 0.99309432 1.16117251 1.00538214 0.96711283 0.97489658\n",
      "  1.03274514]\n",
      " [0.91811143 0.94740917 1.09087585 1.02984852 1.00638968 1.09653088\n",
      "  0.92820856 0.96431168 1.02652255 1.02295647 0.86193808 0.95525935\n",
      "  0.98065155 1.03755099 1.02260049 0.98925295 0.81711981 0.99402204\n",
      "  1.00269174 1.26335968 0.97758574 1.02707522 1.11516717 1.07363499\n",
      "  1.14337395]\n",
      " [0.86316381 0.90101275 0.9411936  0.84973584 1.00352721 0.90766658\n",
      "  1.15954736 0.92049911 0.96485874 1.0801087  0.87876646 0.84464572\n",
      "  1.01521312 1.02283738 1.07677376 1.04968711 1.02661057 0.93030741\n",
      "  1.02003357 1.02621227 0.92703815 1.19477757 1.04472326 0.90249341\n",
      "  1.07732693]\n",
      " [1.0959704  1.03844647 0.97236896 0.92329662 0.98898916 1.03111438\n",
      "  0.99796525 1.14893408 1.06044299 0.91351959 0.89353319 1.04561353\n",
      "  0.9745237  1.06966044 1.04466194 0.98941359 0.91449622 0.85295487\n",
      "  1.01819348 0.87740175 0.91100675 1.01209244 1.00248913 0.8868595\n",
      "  1.10874826]]\n"
     ]
    }
   ],
   "source": [
    "print('lambda')\n",
    "print(lda._lambda_.shape)\n",
    "print(lda._lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma\n",
      "[[6. 6. 6. 6. 6.]\n",
      " [6. 6. 6. 6. 6.]\n",
      " [6. 6. 6. 6. 6.]\n",
      " [6. 6. 6. 6. 6.]\n",
      " [6. 6. 6. 6. 6.]]\n"
     ]
    }
   ],
   "source": [
    "print('gamma')\n",
    "print(lda._gamma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-204.37721599278194\n",
      "59.593369617582205\n"
     ]
    }
   ],
   "source": [
    "perplexity, suff_stats = \\\n",
    "    lda.approx_perplexity(\n",
    "    doc_vocab_count,\n",
    "    sampling=False,\n",
    ")\n",
    "\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-204.37721599278194\n",
      "Before Estep perplexity = 59.593369617582205\n",
      "-202.17223961648543\n",
      "After Estep perplexity = 57.02243531035659\n",
      "CPU times: user 1.98 ms, sys: 410 µs, total: 2.39 ms\n",
      "Wall time: 2.02 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "gamma, suff_stats = \\\n",
    "    lda.e_step_batch(\n",
    "    X = doc_vocab_count,\n",
    "    expec_log_theta= expec_log_theta,\n",
    "    expec_log_beta= expect_log_beta,\n",
    "    verbose = True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_lda = LatentDirichletAllocation(\n",
    "    n_components=5,\n",
    "    random_state=42,\n",
    "    doc_topic_prior= 1,\n",
    "    topic_word_prior= 1,\n",
    ")\n",
    "sklearn_lda._init_latent_vars(n_features = lda.V)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha -> 1\n",
      "eta -> 1\n"
     ]
    }
   ],
   "source": [
    "# alpha \n",
    "print(f\"alpha -> {sklearn_lda.doc_topic_prior}\")\n",
    "print(f\"eta -> {sklearn_lda.topic_word_prior}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- var inf parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda\n",
      "[[1.04708219 0.98292693 0.97347267 0.97347428 1.16278368 1.07526208\n",
      "  0.95052839 1.05181933 1.02101821 0.81760009 0.89893338 1.0283693\n",
      "  1.15026429 0.97429619 0.94330106 1.00778149 0.9378975  0.96782864\n",
      "  0.9953198  0.89475728 1.08105987 0.87968664 0.86986295 1.01644942\n",
      "  1.07222286]\n",
      " [1.01387299 0.98516565 0.96690772 0.95138329 1.10597141 1.02937237\n",
      "  0.95871485 0.93060329 1.05898791 1.1031785  1.09256024 0.91521059\n",
      "  0.96611462 0.94959045 0.9782464  1.08000428 1.13828828 1.03320764\n",
      "  0.93363961 0.99309432 1.16117251 1.00538214 0.96711283 0.97489658\n",
      "  1.03274514]\n",
      " [0.91811143 0.94740917 1.09087585 1.02984852 1.00638968 1.09653088\n",
      "  0.92820856 0.96431168 1.02652255 1.02295647 0.86193808 0.95525935\n",
      "  0.98065155 1.03755099 1.02260049 0.98925295 0.81711981 0.99402204\n",
      "  1.00269174 1.26335968 0.97758574 1.02707522 1.11516717 1.07363499\n",
      "  1.14337395]\n",
      " [0.86316381 0.90101275 0.9411936  0.84973584 1.00352721 0.90766658\n",
      "  1.15954736 0.92049911 0.96485874 1.0801087  0.87876646 0.84464572\n",
      "  1.01521312 1.02283738 1.07677376 1.04968711 1.02661057 0.93030741\n",
      "  1.02003357 1.02621227 0.92703815 1.19477757 1.04472326 0.90249341\n",
      "  1.07732693]\n",
      " [1.0959704  1.03844647 0.97236896 0.92329662 0.98898916 1.03111438\n",
      "  0.99796525 1.14893408 1.06044299 0.91351959 0.89353319 1.04561353\n",
      "  0.9745237  1.06966044 1.04466194 0.98941359 0.91449622 0.85295487\n",
      "  1.01819348 0.87740175 0.91100675 1.01209244 1.00248913 0.8868595\n",
      "  1.10874826]]\n"
     ]
    }
   ],
   "source": [
    "print('lambda')\n",
    "print(sklearn_lda.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (sklearn_lda.components_ == lda._lambda_).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 295 µs, sys: 38 µs, total: 333 µs\n",
      "Wall time: 301 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-202.17223961648543"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sklearn_lda._approx_bound(\n",
    "    doc_vocab_count,\n",
    "    doc_topic_distr = lda._gamma_,\n",
    "    sub_sampling = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.02243531035659"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_lda._perplexity_precomp_distr(\n",
    "    doc_vocab_count, \n",
    "    doc_topic_distr = lda._gamma_,\n",
    "    sub_sampling=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma, suff_stats_ref = \\\n",
    "    sklearn_lda._e_step(\n",
    "    doc_vocab_count,\n",
    "    cal_sstats = False, \n",
    "    random_init = 42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-201.9908836303667"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_lda._approx_bound(\n",
    "    doc_vocab_count,\n",
    "    doc_topic_distr = gamma,\n",
    "    sub_sampling = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.81598275104014"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_lda._perplexity_precomp_distr(\n",
    "    doc_vocab_count, \n",
    "    doc_topic_distr = gamma,\n",
    "    sub_sampling=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
