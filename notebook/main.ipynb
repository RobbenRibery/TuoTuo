{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys \n",
    "if '/Users/ericliu/Desktop/Latent-Dirichilet-Allocation' not in sys.path: \n",
    "    sys.path.append('/Users/ericliu/Desktop/Latent-Dirichilet-Allocation')\n",
    "import torch as tr \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from collections import defaultdict\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lda_model import LDASmoothed \n",
    "from src.generator import doc_generator \n",
    "from src.utils import (\n",
    "    get_vocab_from_docs, \n",
    "    get_np_wct, \n",
    "    data_loader,\n",
    "    text_pipeline, \n",
    "    process_documents,\n",
    ") \n",
    "from src.text_pre_processor import (\n",
    "    remove_accented_chars, \n",
    "    remove_special_characters, \n",
    "    remove_punctuation,\n",
    "    remove_extra_whitespace_tabs,\n",
    "    remove_stopwords,\n",
    ")\n",
    "from pprint import pprint \n",
    "import copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2250 documents in the dataset\n",
      "On average estimated document length is 406.66133333333335 words per document\n",
      "There are 10473 unique vocab in the raw corpus\n"
     ]
    }
   ],
   "source": [
    "docs_raw_dict, raw_word_2_idx, raw_idx_2_word = data_loader('ap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 300 documents in the dataset after processing\n",
      "On average estimated document length is 10.0 words per document after processing\n",
      "There are 2057 unique vocab in the corpus after processing\n"
     ]
    }
   ],
   "source": [
    "result = process_documents(docs_raw_dict, sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic Dirichlet Prior, Alpha\n",
      "torch.Size([5])\n",
      "\n",
      "Word Dirichlet Prior, Eta\n",
      "torch.Size([2057])\n",
      "\n",
      "Var Inf - Word Dirichlet prior, Lambda\n",
      "torch.Size([5, 2057])\n",
      "\n",
      "Var Inf - Topic Dirichlet prior, Gamma\n",
      "torch.Size([300, 5])\n",
      "\n",
      "loop phi\n",
      "looped\n",
      "double\n",
      "Var -Inf - Word wise Topic Multinomial/Categorical, Phi\n",
      "torch.Size([300, 2057, 5])\n"
     ]
    }
   ],
   "source": [
    "lda = LDASmoothed(\n",
    "    docs = result['documents'],\n",
    "    num_topics = 5, \n",
    "    word_ct_dict = result['vocab_doc_count_dict'], \n",
    "    word_ct_array = result['vocab_doc_count_array'],\n",
    ")\n",
    "#LDASmoothed(docs, 3, wct_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'name': 'astrophysics',\n",
       "  'prob': [0.9, 0.025, 0.025, 0.025, 0.025],\n",
       "  'topic': 'science'},)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'name':'astrophysics',\n",
    "                   'prob':[0.90, 0.025, 0.025, 0.025, 0.025],\n",
    "                   'topic':'science',\n",
    "                   },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0->ELBO -27634.997578336068\n",
      "Training started -> ELBO at init is :-27634.997578336068\n",
      "Iteration 0, Delta Gamma = inf, the ELBO is -27634.997578336068\n",
      "Iteration 1, Delta Gamma = 15856.303907289526, the ELBO is -24683.715353594853\n",
      "Iteration 2, Delta Gamma = 2.894657750184471, the ELBO is -24679.619166531564\n",
      "Iteration 3, Delta Gamma = 2.745779955966529, the ELBO is -24675.686550797946\n",
      "Iteration 4, Delta Gamma = 2.7300636271863334, the ELBO is -24671.542362422897\n",
      "Iteration 5, Delta Gamma = 2.823873730229845, the ELBO is -24666.90387943925\n",
      "Iteration 6, Delta Gamma = 3.0345979913178502, the ELBO is -24661.45297503446\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lda\u001b[39m.\u001b[39;49mfit()\n",
      "File \u001b[0;32m~/Desktop/Latent-Dirichilet-Allocation/src/lda_model.py:323\u001b[0m, in \u001b[0;36mLDASmoothed.fit\u001b[0;34m(self, step, threshold, verbose, neg_delta_patience)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[39mif\u001b[39;00m it \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \n\u001b[1;32m    321\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTraining started -> ELBO at init is :\u001b[39m\u001b[39m{\u001b[39;00melbo\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 323\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49me_step(step, threshold, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    324\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm_step(step, threshold, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    326\u001b[0m elbo_hat \u001b[39m=\u001b[39m compute_elbo(\n\u001b[1;32m    327\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gamma_,\n\u001b[1;32m    328\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_phi_,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mword_ct_array\n\u001b[1;32m    333\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Latent-Dirichilet-Allocation/src/lda_model.py:164\u001b[0m, in \u001b[0;36mLDASmoothed.e_step\u001b[0;34m(self, step, threshold, verbose)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mround\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_phi_[d][v]\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    162\u001b[0m     \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mK):\n\u001b[0;32m--> 164\u001b[0m         EqBetak \u001b[39m=\u001b[39m expec_log_dirichlet(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lambda_[k])\n\u001b[1;32m    166\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_phi_[d][v][k] \u001b[39m=\u001b[39m tr\u001b[39m.\u001b[39mexp(EqThetaD[k] \u001b[39m+\u001b[39m EqBetak[v])\n\u001b[1;32m    167\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Latent-Dirichilet-Allocation/src/utils.py:132\u001b[0m, in \u001b[0;36mexpec_log_dirichlet\u001b[0;34m(dirichlet_parm)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute the E[log x_i | dirichlet_parm] for every single dimension, return as a tensor \u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[39mReturns:\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m    tr.Tensor: E[log x|dirichlet_parm] for every dimension of the dirichlet variable \u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39mif\u001b[39;00m dirichlet_parm\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 132\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39msum\u001b[39;49m(dirichlet_parm \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(dirichlet_parm), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mParameters for Dirichilet distribution should be all positive, get \u001b[39m\u001b[39m{\u001b[39;00mdirichlet_parm\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \n\u001b[1;32m    133\u001b[0m \u001b[39melse\u001b[39;00m: \n\u001b[1;32m    134\u001b[0m     \u001b[39massert\u001b[39;00m dirichlet_parm\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39monly vector is accepted, \u001b[39m\u001b[39m{\u001b[39;00mdirichlet_parm\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m matrix is provided.\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/Latent-Dirichilet-Allocation/.venv/lib/python3.8/site-packages/torch/_tensor.py:926\u001b[0m, in \u001b[0;36mTensor.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_get_tracing_state():\n\u001b[1;32m    918\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    919\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIterating over a tensor might cause the trace to be incorrect. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    920\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPassing a tensor of different shape won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt change the number of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    924\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m    925\u001b[0m     )\n\u001b[0;32m--> 926\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39miter\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munbind(\u001b[39m0\u001b[39;49m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lda.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1399, 1.0996, 1.0245, 1.0588, 1.1924, 1.0432, 1.0476, 1.0303, 1.1025,\n",
       "        0.9284, 0.8418, 1.1272, 0.9701, 1.0061, 1.1151, 1.0796, 1.0086, 1.0041,\n",
       "        1.0649, 1.1098], dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda._alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda._eta_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
       "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
       "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
       "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
       "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
       "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
       "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500],\n",
       "         [0.0500, 0.0500, 0.0500,  ..., 0.0500, 0.0500, 0.0500]]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda._phi_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
