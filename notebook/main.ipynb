{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericliu/Desktop/Latent-Dirichilet-Allocation/.venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys \n",
    "if '/Users/ericliu/Desktop/Latent-Dirichilet-Allocation' not in sys.path: \n",
    "    sys.path.append('/Users/ericliu/Desktop/Latent-Dirichilet-Allocation')\n",
    "import torch as tr \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from collections import defaultdict\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lda_model import LDASmoothed \n",
    "from src.generator import doc_generator \n",
    "from src.utils import (\n",
    "    get_vocab_from_docs, \n",
    "    get_np_wct, \n",
    "    data_loader,\n",
    "    text_pipeline, \n",
    "    process_documents,\n",
    ") \n",
    "from src.text_pre_processor import (\n",
    "    remove_accented_chars, \n",
    "    remove_special_characters, \n",
    "    remove_punctuation,\n",
    "    remove_extra_whitespace_tabs,\n",
    "    remove_stopwords,\n",
    ")\n",
    "from pprint import pprint \n",
    "import copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = doc_generator(\n",
    "    M = 3,\n",
    "    L = 20, \n",
    "    topic_prior = tr.tensor([1,1,1,1,1], dtype=tr.double)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1131, 0.0589, 0.0824, 0.1060, 0.0471, 0.0824, 0.0294, 0.1060, 0.0059,\n",
       "         0.0047, 0.0353, 0.0059, 0.0118, 0.0035, 0.0012, 0.0012, 0.0118, 0.0118,\n",
       "         0.0236, 0.0236, 0.0177, 0.0177, 0.0041, 0.0047, 0.0353, 0.0059, 0.0118,\n",
       "         0.0353, 0.0177, 0.0118, 0.0029, 0.0035, 0.0029, 0.0012, 0.0353, 0.0029,\n",
       "         0.0059, 0.0118, 0.0029, 0.0029],\n",
       "        [0.0012, 0.0047, 0.0047, 0.0030, 0.0355, 0.0118, 0.0237, 0.0030, 0.0948,\n",
       "         0.0592, 0.0592, 0.1066, 0.0474, 0.1066, 0.0948, 0.1126, 0.0237, 0.0059,\n",
       "         0.0059, 0.0118, 0.0178, 0.0178, 0.0041, 0.0047, 0.0047, 0.0237, 0.0118,\n",
       "         0.0296, 0.0059, 0.0237, 0.0030, 0.0036, 0.0030, 0.0012, 0.0036, 0.0030,\n",
       "         0.0047, 0.0118, 0.0030, 0.0030],\n",
       "        [0.0014, 0.0057, 0.0043, 0.0036, 0.0143, 0.0071, 0.0286, 0.0036, 0.0071,\n",
       "         0.0043, 0.0214, 0.0014, 0.0428, 0.0043, 0.0143, 0.0014, 0.0500, 0.0999,\n",
       "         0.0999, 0.0571, 0.0857, 0.0857, 0.1285, 0.1285, 0.0057, 0.0014, 0.0143,\n",
       "         0.0071, 0.0071, 0.0071, 0.0036, 0.0143, 0.0036, 0.0014, 0.0043, 0.0036,\n",
       "         0.0043, 0.0143, 0.0036, 0.0036],\n",
       "        [0.0013, 0.0507, 0.0253, 0.0032, 0.0127, 0.0127, 0.0317, 0.0032, 0.0063,\n",
       "         0.0507, 0.0032, 0.0013, 0.0127, 0.0025, 0.0051, 0.0013, 0.0253, 0.0063,\n",
       "         0.0032, 0.0127, 0.0190, 0.0190, 0.0019, 0.0013, 0.0760, 0.0887, 0.0633,\n",
       "         0.0443, 0.0887, 0.0760, 0.1140, 0.1013, 0.0032, 0.0013, 0.0051, 0.0032,\n",
       "         0.0038, 0.0127, 0.0032, 0.0032],\n",
       "        [0.0012, 0.0023, 0.0035, 0.0029, 0.0117, 0.0058, 0.0117, 0.0029, 0.0058,\n",
       "         0.0035, 0.0029, 0.0035, 0.0117, 0.0023, 0.0047, 0.0023, 0.0175, 0.0117,\n",
       "         0.0029, 0.0234, 0.0175, 0.0175, 0.0018, 0.0012, 0.0023, 0.0047, 0.0234,\n",
       "         0.0058, 0.0058, 0.0058, 0.0029, 0.0047, 0.1051, 0.1121, 0.0701, 0.1051,\n",
       "         0.0993, 0.0701, 0.1051, 0.1051]], dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dirichlet(concentration: torch.Size([5]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2737, 0.1182, 0.0215, 0.3038, 0.2829],\n",
       "        [0.0219, 0.4398, 0.1990, 0.3358, 0.0035],\n",
       "        [0.0611, 0.0508, 0.4054, 0.3969, 0.0858]], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: 0 | word: 0 -> topic: health -> word: decongestant\n",
      "Document: 0 | word: 1 -> topic: sport -> word: immunology\n",
      "Document: 0 | word: 2 -> topic: health -> word: genetics\n",
      "Document: 0 | word: 3 -> topic: science -> word: physical\n",
      "Document: 0 | word: 4 -> topic: science -> word: research\n",
      "Document: 0 | word: 5 -> topic: sport -> word: copyright\n",
      "Document: 0 | word: 6 -> topic: science -> word: energy\n",
      "Document: 0 | word: 7 -> topic: sport -> word: football\n",
      "Document: 0 | word: 8 -> topic: science -> word: allergy\n",
      "Document: 0 | word: 9 -> topic: law -> word: evidence\n",
      "Document 0: decongestant immunology genetics physical research copyright energy football allergy evidence\n",
      "\n",
      "Document: 1 | word: 0 -> topic: art -> word: concert\n",
      "Document: 1 | word: 1 -> topic: health -> word: decongestant\n",
      "Document: 1 | word: 2 -> topic: health -> word: bruise\n",
      "Document: 1 | word: 3 -> topic: science -> word: quantum\n",
      "Document: 1 | word: 4 -> topic: sport -> word: evidence\n",
      "Document: 1 | word: 5 -> topic: sport -> word: physical\n",
      "Document: 1 | word: 6 -> topic: sport -> word: infection\n",
      "Document: 1 | word: 7 -> topic: science -> word: physical\n",
      "Document: 1 | word: 8 -> topic: sport -> word: Olympic\n",
      "Document: 1 | word: 9 -> topic: art -> word: Craftsmanship\n",
      "Document 1: concert decongestant bruise quantum evidence physical infection physical Olympic Craftsmanship\n",
      "\n",
      "Document: 2 | word: 0 -> topic: law -> word: accuse\n",
      "Document: 2 | word: 1 -> topic: art -> word: asymmetrical\n",
      "Document: 2 | word: 2 -> topic: art -> word: asymmetrical\n",
      "Document: 2 | word: 3 -> topic: health -> word: evidence\n",
      "Document: 2 | word: 4 -> topic: health -> word: research\n",
      "Document: 2 | word: 5 -> topic: art -> word: asymmetrical\n",
      "Document: 2 | word: 6 -> topic: health -> word: infection\n",
      "Document: 2 | word: 7 -> topic: art -> word: Symmetrical\n",
      "Document: 2 | word: 8 -> topic: health -> word: genetics\n",
      "Document: 2 | word: 9 -> topic: health -> word: research\n",
      "Document 2: accuse asymmetrical asymmetrical evidence research asymmetrical infection Symmetrical genetics research\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = gen.generate_doc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'decongestant immunology genetics physical research copyright energy football allergy evidence',\n",
       " 1: 'concert decongestant bruise quantum evidence physical infection physical Olympic Craftsmanship',\n",
       " 2: 'accuse asymmetrical asymmetrical evidence research asymmetrical infection Symmetrical genetics research'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs_raw_dict, raw_word_2_idx, raw_idx_2_word = data_loader('ap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 documents in the dataset after processing\n",
      "On average estimated document length is 10.0 words per document after processing\n",
      "There are 19 unique vocab in the corpus after processing\n"
     ]
    }
   ],
   "source": [
    "result = process_documents(docs, sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decongestant': [1, 1, 0],\n",
       " 'immunology': [1, 0, 0],\n",
       " 'genetics': [1, 0, 1],\n",
       " 'physical': [1, 2, 0],\n",
       " 'research': [1, 0, 2],\n",
       " 'copyright': [1, 0, 0],\n",
       " 'energy': [1, 0, 0],\n",
       " 'football': [1, 0, 0],\n",
       " 'allergy': [1, 0, 0],\n",
       " 'evidence': [1, 1, 1],\n",
       " 'concert': [0, 1, 0],\n",
       " 'bruise': [0, 1, 0],\n",
       " 'quantum': [0, 1, 0],\n",
       " 'infection': [0, 1, 1],\n",
       " 'Olympic': [0, 1, 0],\n",
       " 'Craftsmanship': [0, 1, 0],\n",
       " 'accuse': [0, 0, 1],\n",
       " 'asymmetrical': [0, 0, 3],\n",
       " 'Symmetrical': [0, 0, 1]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['vocab_doc_count_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 1.],\n",
       "       [1., 2., 0.],\n",
       "       [1., 0., 2.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 1., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 3.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['vocab_doc_count_array']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic Dirichlet Prior, Alpha\n",
      "torch.Size([5])\n",
      "\n",
      "Exchangeable Word Dirichlet Prior, Eta \n",
      "1\n",
      "\n",
      "Var Inf - Word Dirichlet prior, Lambda\n",
      "torch.Size([5, 19])\n",
      "\n",
      "Var Inf - Topic Dirichlet prior, Gamma\n",
      "torch.Size([3, 5])\n",
      "\n",
      "loop phi\n",
      "looped\n",
      "double\n",
      "Var -Inf - Word wise Topic Multinomial/Categorical, Phi\n",
      "torch.Size([3, 19, 5])\n"
     ]
    }
   ],
   "source": [
    "lda = LDASmoothed(\n",
    "    docs = result['documents'],\n",
    "    num_topics = 5, \n",
    "    word_ct_dict = result['vocab_doc_count_dict'], \n",
    "    word_ct_array = result['vocab_doc_count_array'],\n",
    ")\n",
    "#LDASmoothed(docs, 3, wct_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0747, 1.1815, 0.9303, 0.9676, 0.8724], dtype=torch.float64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda._alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.8747, 4.9815, 4.7303, 4.7676, 4.6724],\n",
       "        [4.8747, 4.9815, 4.7303, 4.7676, 4.6724],\n",
       "        [4.8747, 4.9815, 4.7303, 4.7676, 4.6724]], dtype=torch.float64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda._gamma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda._phi_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic Dirichlet Prior, Alpha\n",
      "torch.Size([5])\n",
      "\n",
      "Exchangeable Word Dirichlet Prior, Eta \n",
      "1\n",
      "\n",
      "Var Inf - Word Dirichlet prior, Lambda\n",
      "torch.Size([5, 19])\n",
      "\n",
      "Var Inf - Topic Dirichlet prior, Gamma\n",
      "torch.Size([3, 5])\n",
      "\n",
      "loop phi\n",
      "looped\n",
      "double\n",
      "Var -Inf - Word wise Topic Multinomial/Categorical, Phi\n",
      "torch.Size([3, 19, 5])\n"
     ]
    }
   ],
   "source": [
    "lda = LDASmoothed(\n",
    "    docs = result['documents'],\n",
    "    num_topics = 5, \n",
    "    word_ct_dict = result['vocab_doc_count_dict'], \n",
    "    word_ct_array = result['vocab_doc_count_array'],\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0471, 0.9829, 0.9735, 0.9735, 1.1628], dtype=torch.float64)\n",
      "tensor([[4.8471, 4.7829, 4.7735, 4.7735, 4.9628],\n",
      "        [4.8471, 4.7829, 4.7735, 4.7735, 4.9628],\n",
      "        [4.8471, 4.7829, 4.7735, 4.7735, 4.9628]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "lda._alpha_ = np.random.gamma(shape=100, scale=0.01, size=lda.K)\n",
    "lda._gamma_ = lda._alpha_ + np.ones((lda.M, lda.K)) * result['vocab_to_idx']/ lda.K \n",
    "\n",
    "lda._alpha_ = tr.tensor(lda._alpha_, dtype=tr.double)\n",
    "lda._gamma_ = tr.tensor(lda._gamma_, dtype=tr.double)\n",
    "\n",
    "print(lda._alpha_)\n",
    "print(lda._gamma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.4192192526763|tensor([1.0471, 0.9829, 0.9735, 0.9735, 1.1628], dtype=torch.float64) -> tensor([1.7821, 1.7058, 1.6943, 1.6943, 1.9116], dtype=torch.float64)\n",
      "Iteration 0, Delta Alpha = 1.6317682001101212 elbo is -278.82768267943055\n",
      "72.4192192526763|tensor([1.7821, 1.7058, 1.6943, 1.6943, 1.9116], dtype=torch.float64) -> tensor([2.8356, 2.7569, 2.7449, 2.7449, 2.9664], dtype=torch.float64)\n",
      "Iteration 1, Delta Alpha = 2.352649532593188 elbo is -276.0705562049756\n",
      "72.4192192526763|tensor([2.8356, 2.7569, 2.7449, 2.7449, 2.9664], dtype=torch.float64) -> tensor([3.9752, 3.9027, 3.8917, 3.8917, 4.0992], dtype=torch.float64)\n",
      "Iteration 2, Delta Alpha = 2.554457301341353 elbo is -274.3524646043217\n",
      "72.4192192526763|tensor([3.9752, 3.9027, 3.8917, 3.8917, 4.0992], dtype=torch.float64) -> tensor([4.6827, 4.6166, 4.6068, 4.6068, 4.8002], dtype=torch.float64)\n",
      "Iteration 3, Delta Alpha = 1.5887650484159113 elbo is -273.6558400029852\n",
      "72.4192192526763|tensor([4.6827, 4.6166, 4.6068, 4.6068, 4.8002], dtype=torch.float64) -> tensor([4.8412, 4.7770, 4.7675, 4.7675, 4.9570], dtype=torch.float64)\n",
      "Iteration 4, Delta Alpha = 0.3565116004112243 elbo is -273.5363185133086\n",
      "72.4192192526763|tensor([4.8412, 4.7770, 4.7675, 4.7675, 4.9570], dtype=torch.float64) -> tensor([4.8471, 4.7829, 4.7735, 4.7735, 4.9628], dtype=torch.float64)\n",
      "Iteration 5, Delta Alpha = 0.013171846902684354 elbo is -273.53239090884347\n",
      "72.4192192526763|tensor([4.8471, 4.7829, 4.7735, 4.7735, 4.9628], dtype=torch.float64) -> tensor([4.8471, 4.7829, 4.7735, 4.7735, 4.9628], dtype=torch.float64)\n",
      "Iteration 6, Delta Alpha = 1.6793294751593897e-05 elbo is -273.5323860156641\n",
      "72.4192192526763|tensor([4.8471, 4.7829, 4.7735, 4.7735, 4.9628], dtype=torch.float64) -> tensor([4.8471, 4.7829, 4.7735, 4.7735, 4.9628], dtype=torch.float64)\n",
      "Iteration 7, Delta Alpha = 2.7172943607280292e-11 elbo is -273.53238601565624\n"
     ]
    }
   ],
   "source": [
    "lda.update_alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([199.0945, 100.0088, 199.0314, 298.0643, 297.9187, 100.0088, 100.0088,\n",
       "        100.0088, 100.0088, 298.1493,  99.9743,  99.9743,  99.9743, 199.0503,\n",
       "         99.9743,  99.9743,  99.9450, 297.7011,  99.9450], dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_trained._eta_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[199.2372, 100.0801, 199.1742, 298.2784, 298.1329, 100.0801, 100.0801,\n",
       "         100.0801, 100.0801, 298.3635, 100.0456, 100.0456, 100.0456, 199.1931,\n",
       "         100.0456, 100.0456, 100.0163, 297.9153, 100.0163],\n",
       "        [198.7724,  99.8477, 198.7093, 297.5811, 297.4356,  99.8477,  99.8477,\n",
       "          99.8477,  99.8477, 297.6662,  99.8132,  99.8132,  99.8132, 198.7282,\n",
       "          99.8132,  99.8132,  99.7839, 297.2180,  99.7839],\n",
       "        [199.7479, 100.3355, 199.6849, 299.0445, 298.8990, 100.3355, 100.3355,\n",
       "         100.3355, 100.3355, 299.1296, 100.3010, 100.3010, 100.3010, 199.7038,\n",
       "         100.3010, 100.3010, 100.2717, 298.6814, 100.2717],\n",
       "        [198.9259,  99.9245, 198.8629, 297.8115, 297.6659,  99.9245,  99.9245,\n",
       "          99.9245,  99.9245, 297.8966,  99.8900,  99.8900,  99.8900, 198.8818,\n",
       "          99.8900,  99.8900,  99.8607, 297.4483,  99.8607],\n",
       "        [198.7922,  99.8576, 198.7291, 297.6109, 297.4653,  99.8576,  99.8576,\n",
       "          99.8576,  99.8576, 297.6959,  99.8231,  99.8231,  99.8231, 198.7480,\n",
       "          99.8231,  99.8231,  99.7938, 297.2477,  99.7938]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_trained._lambda_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2710, 0.0386, 0.5264, 0.1154, 0.0485],\n",
       "         [0.2711, 0.0386, 0.5264, 0.1154, 0.0485],\n",
       "         [0.2710, 0.0386, 0.5264, 0.1154, 0.0485],\n",
       "         [0.2710, 0.0386, 0.5264, 0.1154, 0.0485],\n",
       "         [0.2710, 0.0386, 0.5264, 0.1154, 0.0485],\n",
       "         [0.2711, 0.0386, 0.5264, 0.1154, 0.0485],\n",
       "         [0.2711, 0.0386, 0.5264, 0.1154, 0.0485],\n",
       "         [0.2711, 0.0386, 0.5264, 0.1154, 0.0485],\n",
       "         [0.2711, 0.0386, 0.5264, 0.1154, 0.0485],\n",
       "         [0.2710, 0.0386, 0.5264, 0.1154, 0.0485],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.2710, 0.0386, 0.5264, 0.1154, 0.0485],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2710, 0.0386, 0.5264, 0.1154, 0.0485],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2710, 0.0386, 0.5264, 0.1154, 0.0485],\n",
       "         [0.2711, 0.0386, 0.5264, 0.1154, 0.0485],\n",
       "         [0.2711, 0.0386, 0.5264, 0.1154, 0.0485],\n",
       "         [0.2711, 0.0386, 0.5264, 0.1154, 0.0485],\n",
       "         [0.2710, 0.0386, 0.5264, 0.1154, 0.0485],\n",
       "         [0.2711, 0.0386, 0.5264, 0.1154, 0.0485],\n",
       "         [0.2711, 0.0386, 0.5264, 0.1154, 0.0485],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2710, 0.0386, 0.5264, 0.1154, 0.0485],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2710, 0.0386, 0.5264, 0.1154, 0.0485],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2710, 0.0386, 0.5264, 0.1154, 0.0485],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2710, 0.0386, 0.5264, 0.1154, 0.0485],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2711, 0.0386, 0.5264, 0.1154, 0.0485],\n",
       "         [0.2710, 0.0386, 0.5264, 0.1154, 0.0485],\n",
       "         [0.2711, 0.0386, 0.5264, 0.1154, 0.0485]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_trained._phi_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[397.5601, 918.4914, 459.1947, 821.5236, 730.4222],\n",
       "        [398.1572, 919.8720, 459.8845, 822.7584, 731.5199],\n",
       "        [397.5601, 918.4914, 459.1947, 821.5236, 730.4222]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_trained._gamma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
