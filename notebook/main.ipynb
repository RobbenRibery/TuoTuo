{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys \n",
    "if '/Users/ericliu/Desktop/Latent-Dirichilet-Allocation' not in sys.path: \n",
    "    sys.path.append('/Users/ericliu/Desktop/Latent-Dirichilet-Allocation')\n",
    "import torch as tr \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lda_model import LDASmoothed \n",
    "from src.utils import get_vocab_from_docs, get_np_wct \n",
    "from pprint import pprint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['My', 'name', 'is', 'tuo', 'tuo', '.'], ['tuo', 'tuo', 'is', 'cute', '!'], ['Tuo', 'tuo', 'likes', 'to', 'poo', 'a', 'lot', '!'], ['mama', 'bear', 'very', 'tuo', '!']]\n"
     ]
    }
   ],
   "source": [
    "docs = [\n",
    "    ['My name is tuo tuo .'],\n",
    "    ['tuo tuo is cute !'],\n",
    "    ['Tuo tuo likes to poo a lot !'],\n",
    "    ['mama bear very tuo !']\n",
    "]\n",
    "\n",
    "docs = [doc[0].split(' ') for doc in docs]\n",
    "\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'My': [1, 0, 0, 0],\n",
       " 'name': [1, 0, 0, 0],\n",
       " 'is': [1, 1, 0, 0],\n",
       " 'tuo': [2, 2, 1, 1],\n",
       " '.': [1, 0, 0, 0],\n",
       " 'cute': [0, 1, 0, 0],\n",
       " '!': [0, 1, 1, 1],\n",
       " 'Tuo': [0, 0, 1, 0],\n",
       " 'likes': [0, 0, 1, 0],\n",
       " 'to': [0, 0, 1, 0],\n",
       " 'poo': [0, 0, 1, 0],\n",
       " 'a': [0, 0, 1, 0],\n",
       " 'lot': [0, 0, 1, 0],\n",
       " 'mama': [0, 0, 0, 1],\n",
       " 'bear': [0, 0, 0, 1],\n",
       " 'very': [0, 0, 0, 1]}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wct_dict = get_vocab_from_docs(docs)\n",
    "wct_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [2. 2. 1. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 1. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]]\n",
      "{'!': 6,\n",
      " '.': 4,\n",
      " 'My': 0,\n",
      " 'Tuo': 7,\n",
      " 'a': 11,\n",
      " 'bear': 14,\n",
      " 'cute': 5,\n",
      " 'is': 2,\n",
      " 'likes': 8,\n",
      " 'lot': 12,\n",
      " 'mama': 13,\n",
      " 'name': 1,\n",
      " 'poo': 10,\n",
      " 'to': 9,\n",
      " 'tuo': 3,\n",
      " 'very': 15}\n"
     ]
    }
   ],
   "source": [
    "wct_array, w_2_idx = get_np_wct(wct_dict, docs)\n",
    "\n",
    "print(wct_array)\n",
    "pprint(w_2_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 0.0, 0.0],\n",
       "       [1.0, 0.0, 0.0, 0.0],\n",
       "       [1.0, 1.0, 0.0, 0.0],\n",
       "       [2.0, 2.0, 1.0, 1.0],\n",
       "       [1.0, 0.0, 0.0, 0.0],\n",
       "       [0.0, 1.0, 0.0, 0.0],\n",
       "       [0.0, 1.0, 1.0, 1.0],\n",
       "       [0.0, 0.0, 1.0, 0.0],\n",
       "       [0.0, 0.0, 1.0, 0.0],\n",
       "       [0.0, 0.0, 1.0, 0.0],\n",
       "       [0.0, 0.0, 1.0, 0.0],\n",
       "       [0.0, 0.0, 1.0, 0.0],\n",
       "       [0.0, 0.0, 1.0, 0.0],\n",
       "       [0.0, 0.0, 0.0, 1.0],\n",
       "       [0.0, 0.0, 0.0, 1.0],\n",
       "       [0.0, 0.0, 0.0, 1.0]], dtype=object)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wct_array.astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['My', 'name', 'is', 'tuo', 'tuo', '.'], ['tuo', 'tuo', 'is', 'cute', '!'], ['Tuo', 'tuo', 'likes', 'to', 'poo', 'a', 'lot', '!'], ['mama', 'bear', 'very', 'tuo', '!']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 3, 4],\n",
       " [3, 3, 2, 5, 6],\n",
       " [7, 3, 8, 9, 10, 11, 12, 6],\n",
       " [13, 14, 15, 3, 6]]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_in_vocab_indx = docs.copy()\n",
    "print(docs_in_vocab_indx)\n",
    "\n",
    "for id, d in enumerate(docs): \n",
    "\n",
    "    for n in range(len(d)): \n",
    "\n",
    "        docs_in_vocab_indx[id][n] = w_2_idx[docs[id][n]]\n",
    "\n",
    "docs_in_vocab_indx\n",
    "# docs_in_idx = np.array(docs_in_vocab_indx)\n",
    "# docs_in_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_wd_index = np."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic Dirichlet Prior, Alpha\n",
      "torch.Size([1, 3])\n",
      "tensor([[0.9178, 1.1298, 1.0261]], dtype=torch.float64)\n",
      "\n",
      "Word Dirichlet Prior, Eta\n",
      "torch.Size([1, 16])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "Var Inf - Word Dirichlet prior, Lambda\n",
      "torch.Size([3, 16])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "Var Inf - Topic Dirichlet prior, Gamma\n",
      "torch.Size([4, 3])\n",
      "tensor([[6.2511, 6.4631, 6.3595],\n",
      "        [6.2511, 6.4631, 6.3595],\n",
      "        [6.2511, 6.4631, 6.3595],\n",
      "        [6.2511, 6.4631, 6.3595]], dtype=torch.float64)\n",
      "\n",
      "Var -Inf - Word wise Topic Multinomial/Categorical, Phi\n",
      "(4,)\n",
      "[array([[0.33333333, 0.33333333, 0.33333333],\n",
      "       [0.33333333, 0.33333333, 0.33333333],\n",
      "       [0.33333333, 0.33333333, 0.33333333],\n",
      "       [0.33333333, 0.33333333, 0.33333333],\n",
      "       [0.33333333, 0.33333333, 0.33333333],\n",
      "       [0.33333333, 0.33333333, 0.33333333]]), array([[0.33333333, 0.33333333, 0.33333333],\n",
      "       [0.33333333, 0.33333333, 0.33333333],\n",
      "       [0.33333333, 0.33333333, 0.33333333],\n",
      "       [0.33333333, 0.33333333, 0.33333333],\n",
      "       [0.33333333, 0.33333333, 0.33333333]]), array([[0.33333333, 0.33333333, 0.33333333],\n",
      "       [0.33333333, 0.33333333, 0.33333333],\n",
      "       [0.33333333, 0.33333333, 0.33333333],\n",
      "       [0.33333333, 0.33333333, 0.33333333],\n",
      "       [0.33333333, 0.33333333, 0.33333333],\n",
      "       [0.33333333, 0.33333333, 0.33333333],\n",
      "       [0.33333333, 0.33333333, 0.33333333],\n",
      "       [0.33333333, 0.33333333, 0.33333333]]), array([[0.33333333, 0.33333333, 0.33333333],\n",
      "       [0.33333333, 0.33333333, 0.33333333],\n",
      "       [0.33333333, 0.33333333, 0.33333333],\n",
      "       [0.33333333, 0.33333333, 0.33333333],\n",
      "       [0.33333333, 0.33333333, 0.33333333]])]\n"
     ]
    }
   ],
   "source": [
    "lda = LDASmoothed(\n",
    "    docs,\n",
    "    3, \n",
    "    wct_dict, \n",
    "    word_ct_array = wct_array\n",
    ")\n",
    "#LDASmoothed(docs, 3, wct_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Delta Gamma = inf\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "inconsistent tensor size, expected tensor [4] and src [3] to have the same number of elements, but got 4 and 3 elements respectively",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lda\u001b[39m.\u001b[39;49me_step()\n",
      "File \u001b[0;32m~/Desktop/Latent-Dirichilet-Allocation/src/lda_model.py:164\u001b[0m, in \u001b[0;36mLDASmoothed.e_step\u001b[0;34m(self, threshold, verbose)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_phi_[d][n][k] \u001b[39m=\u001b[39m phi_d[n][k]\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m    162\u001b[0m     \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mV): \n\u001b[0;32m--> 164\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lambda_[k][v] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr\u001b[39m.\u001b[39;49mdot(\n\u001b[1;32m    165\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mword_ct_array[v], \n\u001b[1;32m    166\u001b[0m             tr\u001b[39m.\u001b[39;49mfrom_numpy(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_phi_[:][v][k])\u001b[39m.\u001b[39;49mdouble()\n\u001b[1;32m    167\u001b[0m         )    \n\u001b[1;32m    169\u001b[0m \u001b[39m### normalise ### \u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_phi_[d][n] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_phi_[d][n]\u001b[39m/\u001b[39mnp\u001b[39m.\u001b[39msum(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_phi_[d][n])\n",
      "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor size, expected tensor [4] and src [3] to have the same number of elements, but got 4 and 3 elements respectively"
     ]
    }
   ],
   "source": [
    "lda.e_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda._phi_[:][2][-1] = [1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[0.33333333, 0.33333333, 0.33333333],\n",
       "              [0.33333333, 0.33333333, 0.33333333],\n",
       "              [0.33333333, 0.33333333, 0.33333333],\n",
       "              [0.33333333, 0.33333333, 0.33333333],\n",
       "              [0.33333333, 0.33333333, 0.33333333],\n",
       "              [0.33333333, 0.33333333, 0.33333333]]),\n",
       "       array([[0.33333333, 0.33333333, 0.33333333],\n",
       "              [0.33333333, 0.33333333, 0.33333333],\n",
       "              [0.33333333, 0.33333333, 0.33333333],\n",
       "              [0.33333333, 0.33333333, 0.33333333],\n",
       "              [0.33333333, 0.33333333, 0.33333333]]),\n",
       "       array([[0.33333333, 0.33333333, 0.33333333],\n",
       "              [0.33333333, 0.33333333, 0.33333333],\n",
       "              [0.33333333, 0.33333333, 0.33333333],\n",
       "              [0.33333333, 0.33333333, 0.33333333],\n",
       "              [0.33333333, 0.33333333, 0.33333333],\n",
       "              [0.33333333, 0.33333333, 0.33333333],\n",
       "              [0.33333333, 0.33333333, 0.33333333],\n",
       "              [1.        , 1.        , 1.        ]]),\n",
       "       array([[0.33333333, 0.33333333, 0.33333333],\n",
       "              [0.33333333, 0.33333333, 0.33333333],\n",
       "              [0.33333333, 0.33333333, 0.33333333],\n",
       "              [0.33333333, 0.33333333, 0.33333333],\n",
       "              [0.33333333, 0.33333333, 0.33333333]])], dtype=object)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda._phi_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda._phi_[:][2][-1].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tr.tensor(lda._phi_[:][2][-1])\n",
    "x1 = x.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1[1]= 1e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 1.0000e+08, 1.0000e+00], dtype=torch.float64)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
