{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys \n",
    "if '/Users/ericliu/Desktop/Latent-Dirichilet-Allocation' not in sys.path: \n",
    "    sys.path.append('/Users/ericliu/Desktop/Latent-Dirichilet-Allocation')\n",
    "import torch as tr \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "from scipy.special import psi, polygamma, gammaln, loggamma\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from src.lda_model import LDASmoothed \n",
    "from src.generator import doc_generator \n",
    "from src.utils import (\n",
    "    get_vocab_from_docs, \n",
    "    get_np_wct, \n",
    "    data_loader,\n",
    "    text_pipeline, \n",
    "    process_documents,\n",
    ") \n",
    "from src.text_pre_processor import (\n",
    "    remove_accented_chars, \n",
    "    remove_special_characters, \n",
    "    remove_punctuation,\n",
    "    remove_extra_whitespace_tabs,\n",
    "    remove_stopwords,\n",
    ")\n",
    "from pprint import pprint \n",
    "import copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: 0 | word: 0 -> topic: health -> word: contagious\n",
      "Document: 0 | word: 1 -> topic: law -> word: divorce\n",
      "Document: 0 | word: 2 -> topic: sport -> word: asymmetrical\n",
      "Document: 0 | word: 3 -> topic: science -> word: bruise\n",
      "Document: 0 | word: 4 -> topic: science -> word: infection\n",
      "Document: 0 | word: 5 -> topic: law -> word: bankrupt\n",
      "Document: 0 | word: 6 -> topic: art -> word: asymmetrical\n",
      "Document: 0 | word: 7 -> topic: science -> word: quantum\n",
      "Document: 0 | word: 8 -> topic: law -> word: contract\n",
      "Document: 0 | word: 9 -> topic: science -> word: scientst\n",
      "Document 0: contagious divorce asymmetrical bruise infection bankrupt asymmetrical quantum contract scientst\n",
      "\n",
      "Document: 1 | word: 0 -> topic: sport -> word: game\n",
      "Document: 1 | word: 1 -> topic: science -> word: bruise\n",
      "Document: 1 | word: 2 -> topic: sport -> word: Symmetrical\n",
      "Document: 1 | word: 3 -> topic: sport -> word: exercise\n",
      "Document: 1 | word: 4 -> topic: science -> word: scientst\n",
      "Document: 1 | word: 5 -> topic: sport -> word: bruise\n",
      "Document: 1 | word: 6 -> topic: science -> word: astrophysics\n",
      "Document: 1 | word: 7 -> topic: art -> word: content\n",
      "Document: 1 | word: 8 -> topic: health -> word: exercise\n",
      "Document: 1 | word: 9 -> topic: sport -> word: football\n",
      "Document 1: game bruise Symmetrical exercise scientst bruise astrophysics content exercise football\n",
      "\n",
      "Document: 2 | word: 0 -> topic: health -> word: appetite\n",
      "Document: 2 | word: 1 -> topic: art -> word: copyright\n",
      "Document: 2 | word: 2 -> topic: law -> word: bankrupt\n",
      "Document: 2 | word: 3 -> topic: law -> word: accuse\n",
      "Document: 2 | word: 4 -> topic: health -> word: appetite\n",
      "Document: 2 | word: 5 -> topic: health -> word: research\n",
      "Document: 2 | word: 6 -> topic: health -> word: electricity\n",
      "Document: 2 | word: 7 -> topic: health -> word: appetite\n",
      "Document: 2 | word: 8 -> topic: health -> word: injection\n",
      "Document: 2 | word: 9 -> topic: law -> word: bruise\n",
      "Document 2: appetite copyright bankrupt accuse appetite research electricity appetite injection bruise\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gen = doc_generator(\n",
    "    M = 3,\n",
    "    L = 20, \n",
    "    topic_prior = tr.tensor([1,1,1,1,1], dtype=tr.double)\n",
    ")\n",
    "\n",
    "docs = gen.generate_doc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 documents in the dataset after processing\n",
      "On average estimated document length is 10.0 words per document after processing\n",
      "There are 21 unique vocab in the corpus after processing\n"
     ]
    }
   ],
   "source": [
    "result = process_documents(docs, sample=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "def init_lda(docs, vocab, n_topic, gibbs=False, random_state=0):\n",
    "    if gibbs:\n",
    "        global V, k, N, M, alpha, eta, n_iw, n_di\n",
    "    else:\n",
    "        global V, k, N, M, alpha, beta, gamma, phi\n",
    "        \n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    V = len(vocab)\n",
    "    k = n_topic  # number of topics\n",
    "    N = np.array([doc.shape[0] for doc in docs])\n",
    "    M = len(docs)\n",
    "\n",
    "    print(f\"V: {V}\\nk: {k}\\nN: {N[:10]}...\\nM: {M}\")\n",
    "\n",
    "    # initialize α, β\n",
    "    np.random.random(42)\n",
    "    if gibbs:\n",
    "        alpha = np.random.gamma(shape=100, scale=0.01, size=1)  # one for all k\n",
    "        eta = np.random.gamma(shape=100, scale=0.01, size=1)  # one for all V\n",
    "        print(f\"α: {alpha}\\nη: {eta}\")\n",
    "        \n",
    "        n_iw = np.zeros((k, V), dtype=int)\n",
    "        n_di = np.zeros((M, k), dtype=int)\n",
    "        print(f\"n_iw: dim {n_iw.shape}\\nn_di: dim {n_di.shape}\")\n",
    "    else:\n",
    "        alpha = np.random.gamma(shape=100, scale=0.01, size=k) #np.random.rand(k)\n",
    "        beta = np.random.dirichlet(np.ones(V), k)\n",
    "        print(f\"α: dim {alpha.shape}\\nβ: dim {beta.shape}\")\n",
    "\n",
    "        # initialize ϕ, γ\n",
    "        ## ϕ: (M x max(N) x k) arrays with zero paddings on the right\n",
    "        gamma = alpha + np.ones((M, k)) * V / k\n",
    "\n",
    "        phi = np.ones((M, max(N), k)) / k\n",
    "        for m, N_d in enumerate(N):\n",
    "            phi[m, N_d:, :] = 0  # zero padding for vectorized operations\n",
    "\n",
    "        print(f\"γ: dim {gamma.shape}\\nϕ: dim ({len(phi)}, N_d, {phi[0].shape[1]})\")\n",
    "\n",
    "def E_step(docs, phi, gamma, alpha, beta):\n",
    "    \"\"\"\n",
    "    Minorize the joint likelihood function via variational inference.\n",
    "    This is the E-step of variational EM algorithm for LDA.\n",
    "    \"\"\"\n",
    "    # optimize phi\n",
    "    for m in range(M):\n",
    "        #print(N[m], docs[m])\n",
    "        phi[m, :N[m], :] = (beta[:, docs[m]] * np.exp(\n",
    "            psi(gamma[m, :]) - psi(gamma[m, :].sum())\n",
    "        ).reshape(-1, 1)).T\n",
    "\n",
    "        # Normalize phi\n",
    "        phi[m, :N[m]] /= phi[m, :N[m]].sum(axis=1).reshape(-1, 1)\n",
    "        if np.any(np.isnan(phi)):\n",
    "            raise ValueError(\"phi nan\")\n",
    "        \n",
    "        \n",
    "\n",
    "    # optimize gamma\n",
    "    gamma = alpha + phi.sum(axis=1)\n",
    "\n",
    "    \n",
    "\n",
    "    return phi, gamma\n",
    "\n",
    "\n",
    "def M_step(docs, phi, gamma, alpha, beta, M):\n",
    "    \"\"\"\n",
    "    maximize the lower bound of the likelihood.\n",
    "    This is the M-step of variational EM algorithm for (smoothed) LDA.\n",
    "    \n",
    "    update of alpha follows from appendix A.2 of Blei et al., 2003.\n",
    "    \"\"\"\n",
    "    # update alpha\n",
    "    alpha = _update(alpha, gamma, M)\n",
    "    \n",
    "    # update beta\n",
    "    for j in range(V):\n",
    "        beta[:, j] = np.array([_phi_dot_w(docs, phi, m, j) for m in range(M)]).sum(axis=0)\n",
    "    beta /= beta.sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "    return alpha, beta\n",
    "\n",
    "def _update(var, vi_var, const, max_iter=10000, tol=1e-6):\n",
    "    \"\"\"\n",
    "    From appendix A.2 of Blei et al., 2003.\n",
    "    For hessian with shape `H = diag(h) + 1z1'`\n",
    "    \n",
    "    To update alpha, input var=alpha and vi_var=gamma, const=M.\n",
    "    To update eta, input var=eta and vi_var=lambda, const=k.\n",
    "    \"\"\"\n",
    "    for _ in range(max_iter):\n",
    "        # store old value\n",
    "        var0 = var.copy()\n",
    "        \n",
    "        # g: gradient \n",
    "        psi_sum = psi(vi_var.sum(axis=1)).reshape(-1, 1)\n",
    "        g = const * (psi(var.sum()) - psi(var)) \\\n",
    "            + (psi(vi_var) - psi_sum).sum(axis=0)\n",
    "\n",
    "        # H = diag(h) + 1z1'\n",
    "        z = const * polygamma(1, var.sum())  # z: Hessian constant component\n",
    "        h = -const * polygamma(1, var)       # h: Hessian diagonal component\n",
    "        c = (g / h).sum() / (1./z + (1./h).sum())\n",
    "\n",
    "        # update var\n",
    "        var -= (g - c) / h\n",
    "        print(f\"{vi_var.sum()}|{var0} -> {var}\")\n",
    "        \n",
    "        # check convergence\n",
    "        err = np.sqrt(np.mean((var - var0) ** 2))\n",
    "        crit = err < tol\n",
    "        if crit:\n",
    "            break\n",
    "    else:\n",
    "        warnings.warn(f\"max_iter={max_iter} reached: values might not be optimal.\")\n",
    "    \n",
    "    #print(err)\n",
    "    return var\n",
    "\n",
    "def _phi_dot_w(docs, phi, d, j):\n",
    "    \"\"\"\n",
    "    \\sum_{n=1}^{N_d} ϕ_{dni} w_{dn}^j\n",
    "    \"\"\"\n",
    "    # doc = np.zeros(docs[m].shape[0] * V, dtype=int)\n",
    "    # doc[np.arange(0, docs[m].shape[0] * V, V) + docs[m]] = 1\n",
    "    # doc = doc.reshape(-1, V)\n",
    "    # lam += phi[m, :N[m], :].T @ doc\n",
    "    return (docs[d] == j) @ phi[d, :N[d], :]\n",
    "\n",
    "def dg(gamma, d, i):\n",
    "    \"\"\"\n",
    "    E[log θ_t] where θ_t ~ Dir(gamma)\n",
    "    \"\"\"\n",
    "    return psi(gamma[d, i]) - psi(np.sum(gamma[d, :]))\n",
    "\n",
    "\n",
    "def dl(lam, i, w_n):\n",
    "    \"\"\"\n",
    "    E[log β_t] where β_t ~ Dir(lam)\n",
    "    \"\"\"\n",
    "    return psi(lam[i, w_n]) - psi(np.sum(lam[i, :]))\n",
    "\n",
    "def vlb(docs, phi, gamma, alpha, beta, M, N, k):\n",
    "    \"\"\"\n",
    "    Average variational lower bound for joint log likelihood.\n",
    "    \"\"\"\n",
    "    lb = 0\n",
    "    for d in range(M):\n",
    "        lb += (\n",
    "            gammaln(np.sum(alpha))\n",
    "            - np.sum(gammaln(alpha))\n",
    "            + np.sum([(alpha[i] - 1) * dg(gamma, d, i) for i in range(k)])\n",
    "        )\n",
    "\n",
    "        lb -= (\n",
    "            gammaln(np.sum(gamma[d, :]))\n",
    "            - np.sum(gammaln(gamma[d, :]))\n",
    "            + np.sum([(gamma[d, i] - 1) * dg(gamma, d, i) for i in range(k)])\n",
    "        )\n",
    "\n",
    "        for n in range(N[d]):\n",
    "            w_n = int(docs[d][n])\n",
    "\n",
    "            lb += np.sum([phi[d][n, i] * dg(gamma, d, i) for i in range(k)])\n",
    "            lb += np.sum([phi[d][n, i] * np.log(beta[i, w_n]) for i in range(k)])\n",
    "            lb -= np.sum([phi[d][n, i] * np.log(phi[d][n, i]) for i in range(k)])\n",
    "\n",
    "    return lb / M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contagious': 0,\n",
       " 'divorce': 1,\n",
       " 'asymmetrical': 2,\n",
       " 'bruise': 3,\n",
       " 'infection': 4,\n",
       " 'bankrupt': 5,\n",
       " 'quantum': 6,\n",
       " 'contract': 7,\n",
       " 'scientst': 8,\n",
       " 'game': 9,\n",
       " 'Symmetrical': 10,\n",
       " 'exercise': 11,\n",
       " 'astrophysics': 12,\n",
       " 'content': 13,\n",
       " 'football': 14,\n",
       " 'appetite': 15,\n",
       " 'copyright': 16,\n",
       " 'accuse': 17,\n",
       " 'research': 18,\n",
       " 'electricity': 19,\n",
       " 'injection': 20}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['vocab_to_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'contagious divorce asymmetrical bruise infection bankrupt asymmetrical quantum contract scientst',\n",
       " 1: 'game bruise Symmetrical exercise scientst bruise astrophysics content exercise football',\n",
       " 2: 'appetite copyright bankrupt accuse appetite research electricity appetite injection bruise'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 2, 3, 4, 5, 2, 6, 7, 8]),\n",
       " array([ 9,  3, 10, 11,  8,  3, 12, 13, 11, 14]),\n",
       " array([15, 16,  5, 17, 15, 18, 19, 15, 20,  3])]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_np = []\n",
    "for doc in result['documents']: \n",
    "\n",
    "    doc_idx = []\n",
    "    for n in range(len(doc)): \n",
    "\n",
    "        doc_idx.append(result['vocab_to_idx'][doc[n]])\n",
    "\n",
    "    \n",
    "    docs_np.append(np.array(doc_idx))\n",
    "docs_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  2,  6,  7,  8],\n",
       "       [ 9,  3, 10, 11,  8,  3, 12, 13, 11, 14],\n",
       "       [15, 16,  5, 17, 15, 18, 19, 15, 20,  3]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = np.array(docs_np)\n",
    "docs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V: 21\n",
      "k: 5\n",
      "N: [10 10 10]...\n",
      "M: 3\n",
      "α: dim (5,)\n",
      "β: dim (5, 21)\n",
      "γ: dim (3, 5)\n",
      "ϕ: dim (3, N_d, 5)\n"
     ]
    }
   ],
   "source": [
    "init_lda(docs, set(result['vocab_to_idx'].keys()), n_topic=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9623354 , 1.01235711, 0.95849651, 0.96679042, 0.8358445 ])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1623354 , 5.21235711, 5.15849651, 5.16679042, 5.0358445 ],\n",
       "       [5.1623354 , 5.21235711, 5.15849651, 5.16679042, 5.0358445 ],\n",
       "       [5.1623354 , 5.21235711, 5.15849651, 5.16679042, 5.0358445 ]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2]],\n",
       "\n",
       "       [[0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2]],\n",
       "\n",
       "       [[0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "print(len(result['vocab_to_idx']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.02346479 0.39878536 0.03673691 0.40578283 0.13523011]\n",
      "  [0.09748157 0.02263331 0.30599004 0.31658291 0.25731217]\n",
      "  [0.06189957 0.1591698  0.00595232 0.65660641 0.1163719 ]\n",
      "  [0.20910445 0.03441702 0.29042605 0.20360155 0.26245093]\n",
      "  [0.13450658 0.2200715  0.001805   0.52002753 0.12358938]\n",
      "  [0.23372354 0.0640161  0.351082   0.22637095 0.12480742]\n",
      "  [0.06189957 0.1591698  0.00595232 0.65660641 0.1163719 ]\n",
      "  [0.05497438 0.10214811 0.05140853 0.53584767 0.25562131]\n",
      "  [0.04471861 0.18800969 0.28582745 0.23317971 0.24826454]\n",
      "  [0.02832183 0.02184718 0.66049108 0.11671266 0.17262725]]\n",
      "\n",
      " [[0.28197815 0.42363945 0.0628852  0.21516511 0.01633208]\n",
      "  [0.20910445 0.03441702 0.29042605 0.20360155 0.26245093]\n",
      "  [0.04256281 0.32564044 0.20459985 0.00484826 0.42234865]\n",
      "  [0.08997463 0.1725226  0.30693246 0.12896522 0.30160509]\n",
      "  [0.02832183 0.02184718 0.66049108 0.11671266 0.17262725]\n",
      "  [0.20910445 0.03441702 0.29042605 0.20360155 0.26245093]\n",
      "  [0.06495993 0.14234735 0.09986904 0.1332227  0.55960098]\n",
      "  [0.69958767 0.05459167 0.0854849  0.12177839 0.03855737]\n",
      "  [0.08997463 0.1725226  0.30693246 0.12896522 0.30160509]\n",
      "  [0.01749248 0.19992505 0.43530648 0.14405641 0.20321958]]\n",
      "\n",
      " [[0.2794644  0.55363069 0.07579024 0.07516394 0.01595073]\n",
      "  [0.03519901 0.18184069 0.54355025 0.0443299  0.19508015]\n",
      "  [0.23372354 0.0640161  0.351082   0.22637095 0.12480742]\n",
      "  [0.56501004 0.22576757 0.15089104 0.04666257 0.01166879]\n",
      "  [0.2794644  0.55363069 0.07579024 0.07516394 0.01595073]\n",
      "  [0.21364237 0.06497908 0.09932858 0.24921691 0.37283306]\n",
      "  [0.43631356 0.19885385 0.16235724 0.09060405 0.1118713 ]\n",
      "  [0.2794644  0.55363069 0.07579024 0.07516394 0.01595073]\n",
      "  [0.3040555  0.15225294 0.13772863 0.24447408 0.16148885]\n",
      "  [0.20910445 0.03441702 0.29042605 0.20360155 0.26245093]]]\n",
      "\n",
      "\n",
      "[[1.9124303  2.38262496 2.95416822 4.83810904 2.64849141]\n",
      " [2.69539643 2.5942275  3.70185009 2.36770747 3.37664244]\n",
      " [3.79777707 3.59537643 2.921231   2.29754225 2.12389718]]\n"
     ]
    }
   ],
   "source": [
    "phi, gamma = E_step(docs, phi, gamma, alpha, beta)\n",
    "print(phi)\n",
    "print()\n",
    "print()\n",
    "print(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.04708219 0.98292693 0.97347267 0.97347428 1.16278368]\n",
      "[[5.24708219 5.18292693 5.17347267 5.17347428 5.36278368]\n",
      " [5.24708219 5.18292693 5.17347267 5.17347428 5.36278368]\n",
      " [5.24708219 5.18292693 5.17347267 5.17347428 5.36278368]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "_alpha_ = np.random.gamma(shape=100, scale=0.01, size=5)\n",
    "_gamma_ = _alpha_ + np.ones((M, k)) * 21 / k\n",
    "\n",
    "print(_alpha_)\n",
    "print(_gamma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.4192192526763|[1.04708219 0.98292693 0.97347267 0.97347428 1.16278368] -> [1.79562569 1.71883122 1.70721122 1.70721321 1.92565069]\n",
      "78.4192192526763|[1.79562569 1.71883122 1.70721122 1.70721321 1.92565069] -> [2.89706016 2.81739023 2.80519713 2.80519922 3.0290319 ]\n",
      "78.4192192526763|[2.89706016 2.81739023 2.80519713 2.80519922 3.0290319 ] -> [4.15126141 4.07750791 4.06632234 4.06632425 4.27649846]\n",
      "78.4192192526763|[4.15126141 4.07750791 4.06632234 4.06632425 4.27649846] -> [5.00796502 4.94131996 4.93140917 4.93141086 5.12604242]\n",
      "78.4192192526763|[5.00796502 4.94131996 4.93140917 4.93141086 5.12604242] -> [5.23567369 5.17138297 5.16190351 5.16190513 5.35149999]\n",
      "78.4192192526763|[5.23567369 5.17138297 5.16190351 5.16190513 5.35149999] -> [5.24705619 5.18290058 5.17344626 5.17344787 5.36275799]\n",
      "78.4192192526763|[5.24705619 5.18290058 5.17344626 5.17344787 5.36275799] -> [5.24708219 5.18292693 5.17347267 5.17347428 5.36278368]\n",
      "78.4192192526763|[5.24708219 5.18292693 5.17347267 5.17347428 5.36278368] -> [5.24708219 5.18292693 5.17347267 5.17347428 5.36278368]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5.24708219, 5.18292693, 5.17347267, 5.17347428, 5.36278368])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_update(_alpha_, _gamma_, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "V = 19 \n",
    "print(k)\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[[1.04708219 0.98292693 0.97347267 0.97347428 1.16278368 1.07526208\n",
      "  0.95052839 1.05181933 1.02101821 0.81760009 0.89893338 1.0283693\n",
      "  1.15026429 0.97429619 0.94330106 1.00778149 0.9378975  0.96782864\n",
      "  0.9953198 ]\n",
      " [0.89475728 1.08105987 0.87968664 0.86986295 1.01644942 1.07222286\n",
      "  1.01387299 0.98516565 0.96690772 0.95138329 1.10597141 1.02937237\n",
      "  0.95871485 0.93060329 1.05898791 1.1031785  1.09256024 0.91521059\n",
      "  0.96611462]\n",
      " [0.94959045 0.9782464  1.08000428 1.13828828 1.03320764 0.93363961\n",
      "  0.99309432 1.16117251 1.00538214 0.96711283 0.97489658 1.03274514\n",
      "  0.91811143 0.94740917 1.09087585 1.02984852 1.00638968 1.09653088\n",
      "  0.92820856]\n",
      " [0.96431168 1.02652255 1.02295647 0.86193808 0.95525935 0.98065155\n",
      "  1.03755099 1.02260049 0.98925295 0.81711981 0.99402204 1.00269174\n",
      "  1.26335968 0.97758574 1.02707522 1.11516717 1.07363499 1.14337395\n",
      "  0.86316381]\n",
      " [0.90101275 0.9411936  0.84973584 1.00352721 0.90766658 1.15954736\n",
      "  0.92049911 0.96485874 1.0801087  0.87876646 0.84464572 1.01521312\n",
      "  1.02283738 1.07677376 1.04968711 1.02661057 0.93030741 1.02003357\n",
      "  1.02621227]]\n"
     ]
    }
   ],
   "source": [
    "_eta_ = 1\n",
    "np.random.seed(42)\n",
    "_lambda_ = np.random.gamma(shape=100, scale=0.01, size=(k, V))\n",
    "\n",
    "print(_eta_)\n",
    "print(_lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.04708219, 0.98292693, 0.97347267, 0.97347428, 1.16278368,\n",
       "       1.07526208, 0.95052839, 1.05181933, 1.02101821, 0.81760009,\n",
       "       0.89893338, 1.0283693 , 1.15026429, 0.97429619, 0.94330106,\n",
       "       1.00778149, 0.9378975 , 0.96782864, 0.9953198 ])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_lambda_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _update_eta(var, vi_var, const, max_iter=10000, tol=1e-9):\n",
    "    \"\"\"\n",
    "    From appendix A.2 of Blei et al., 2003.\n",
    "    For hessian with shape `H = diag(h) + 1z1'`\n",
    "    \n",
    "    To update alpha, input var=alpha and vi_var=gamma, const=M.\n",
    "    To update eta, input var=eta and vi_var=lambda, const=k.\n",
    "    \"\"\"\n",
    "    for _ in range(max_iter):\n",
    "        # store old value\n",
    "        var0 = var\n",
    "        \n",
    "        # g: gradient \n",
    "        psi_sum = psi(vi_var.sum(axis=1)).reshape(-1, 1)\n",
    "        g = const * (V*psi(V*var) - V*psi(var)) + np.sum(psi(vi_var)) - np.sum(V*(psi_sum))\n",
    "\n",
    "        h = const * (V**2 * polygamma(1, V*var) - V * polygamma(1, var))\n",
    "\n",
    "        # # update var\n",
    "        var -= g/h\n",
    "        print(f\"grad:{g}, hessian:{h}, eta:old{var0} -> {var}\")\n",
    "\n",
    "        if var == np.inf or var == -np.inf: \n",
    "            raise ValueError(f\"Grad -> {g}, Hessian -> {h}, overflow\")\n",
    "        \n",
    "        # check convergence\n",
    "        err = np.sqrt(np.mean((var - var0) ** 2))\n",
    "        crit = err < tol\n",
    "        if crit:\n",
    "            break\n",
    "    else:\n",
    "        warnings.warn(f\"max_iter={max_iter} reached: values might not be optimal.\")\n",
    "    \n",
    "    #print(err)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8517960407552891, -58.72490095253988, 1 -> 0.985495147255443\n",
      "0.013704776840540944, -60.62945883574141, 0.985495147255443 -> 0.9857211888052723\n",
      "3.433071356084838e-06, -60.599086980475064, 0.9857211888052723 -> 0.9857212454574683\n",
      "2.2737367544323206e-13, -60.59907937125736, 0.9857212454574683 -> 0.9857212454574721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9857212454574721"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_update_eta(1, _lambda_, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.20747180094638|[0.9623354  1.01235711 0.95849651 0.96679042 0.8358445 ] -> [1.30246263 1.3405214  1.47983028 1.40021756 1.205965  ]\n",
      "44.20747180094638|[1.30246263 1.3405214  1.47983028 1.40021756 1.205965  ] -> [1.54513779 1.57450865 1.90501955 1.72630043 1.48332952]\n",
      "44.20747180094638|[1.54513779 1.57450865 1.90501955 1.72630043 1.48332952] -> [1.62256447 1.64941434 2.05354967 1.83332462 1.57408585]\n",
      "44.20747180094638|[1.62256447 1.64941434 2.05354967 1.83332462 1.57408585] -> [1.62825527 1.65494497 2.06526233 1.84131556 1.5808414 ]\n",
      "44.20747180094638|[1.62825527 1.65494497 2.06526233 1.84131556 1.5808414 ] -> [1.62828373 1.65497279 2.06532493 1.84135584 1.58087532]\n",
      "44.20747180094638|[1.62828373 1.65497279 2.06532493 1.84135584 1.58087532] -> [1.62828373 1.65497279 2.06532493 1.84135585 1.58087532]\n",
      " 000:  variational_lb: -30.466,  error:  inf\n",
      "56.31243784243602|[1.62828373 1.65497279 2.06532493 1.84135585 1.58087532] -> [1.79875897 1.68688547 2.21049485 1.95892711 1.67421148]\n",
      "56.31243784243602|[1.79875897 1.68688547 2.21049485 1.95892711 1.67421148] -> [1.81765057 1.69345312 2.22570646 1.97130024 1.68403508]\n",
      "56.31243784243602|[1.81765057 1.69345312 2.22570646 1.97130024 1.68403508] -> [1.8178349  1.69352158 2.22584421 1.97141248 1.68412408]\n",
      "56.31243784243602|[1.8178349  1.69352158 2.22584421 1.97141248 1.68412408] -> [1.81783492 1.69352158 2.22584422 1.97141249 1.68412409]\n",
      " 001:  variational_lb: -30.395,  error:  0.070\n",
      " ========== TRAINING FINISHED ==========\n",
      "CPU times: user 5.17 ms, sys: 600 µs, total: 5.77 ms\n",
      "Wall time: 5.36 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N_EPOCH = 1000\n",
    "TOL = 0.1\n",
    "\n",
    "verbose = True\n",
    "lb = -np.inf\n",
    "\n",
    "for epoch in range(N_EPOCH): \n",
    "    # store old value\n",
    "    lb_old = lb \n",
    "    \n",
    "    # Variational EM\n",
    "    phi, gamma = E_step(docs, phi, gamma, alpha, beta)\n",
    "    alpha, beta = M_step(docs, phi, gamma, alpha, beta, M)\n",
    "    \n",
    "    # check anomaly\n",
    "    if np.any(np.isnan(alpha)):\n",
    "        print(\"NaN detected: alpha\")\n",
    "        break\n",
    "    \n",
    "    # check convergence\n",
    "    lb = vlb(docs, phi, gamma, alpha, beta, M, N, k)\n",
    "    err = abs(lb - lb_old)\n",
    "    \n",
    "    # check anomaly\n",
    "    if np.isnan(lb):\n",
    "        print(\"NaN detected: lb\")\n",
    "        break\n",
    "        \n",
    "    if verbose:\n",
    "        print(f\"{epoch: 04}:  variational_lb: {lb: .3f},  error: {err: .3f}\")\n",
    "    \n",
    "    if err < TOL:\n",
    "        break\n",
    "else:\n",
    "    warnings.warn(f\"max_iter reached: values might not be optimal.\")\n",
    "\n",
    "print(\" ========== TRAINING FINISHED ==========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.81783492, 1.69352158, 2.22584422, 1.97141249, 1.68412409])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.42779378e-04, 3.43280348e-03, 2.79751112e-03, 1.62539236e-01,\n",
       "        3.65500141e-03, 1.02784297e-01, 1.41854097e-03, 1.85048907e-03,\n",
       "        4.80505029e-03, 6.15607135e-02, 5.36133095e-03, 2.39587566e-02,\n",
       "        8.22072207e-03, 1.31886279e-01, 2.32612299e-03, 2.12126430e-01,\n",
       "        1.73727492e-02, 1.36573229e-01, 1.06016533e-01, 8.47878226e-03,\n",
       "        2.09264206e-03],\n",
       "       [2.92057339e-02, 1.84399698e-03, 1.66429635e-02, 3.10141808e-02,\n",
       "        1.38354602e-02, 3.51584890e-02, 6.09814422e-03, 1.79996576e-02,\n",
       "        5.54881825e-03, 9.75809627e-02, 4.32774044e-02, 4.84697427e-02,\n",
       "        1.90061567e-02, 1.08583629e-02, 2.80497473e-02, 4.14968547e-01,\n",
       "        8.86249182e-02, 5.38886981e-02, 3.18409848e-02, 4.78853214e-03,\n",
       "        1.29849833e-03],\n",
       "       [2.78313666e-03, 2.57882891e-02, 6.43812551e-04, 2.10840299e-01,\n",
       "        1.17384486e-04, 8.86294806e-02, 3.17472098e-03, 2.83068116e-02,\n",
       "        2.08087386e-01, 2.11723119e-02, 3.97447087e-02, 1.26042984e-01,\n",
       "        1.94906778e-02, 2.48529846e-02, 8.92705102e-02, 1.51838943e-02,\n",
       "        7.08075156e-02, 9.62663394e-03, 1.30095436e-02, 1.86622327e-03,\n",
       "        5.60690878e-04],\n",
       "       [1.02550432e-01, 8.90050403e-02, 2.36913618e-01, 8.69229516e-02,\n",
       "        1.12816094e-01, 8.23005747e-02, 1.10388442e-01, 7.70352813e-02,\n",
       "        4.20598169e-02, 1.30413358e-02, 1.69546983e-04, 9.53408082e-03,\n",
       "        4.68063408e-03, 6.37367261e-03, 5.31833686e-03, 5.16641310e-03,\n",
       "        1.98128093e-03, 1.02138463e-03, 1.11988910e-02, 7.78351297e-04,\n",
       "        7.43820556e-04],\n",
       "       [1.22600335e-02, 2.59514647e-02, 1.50628602e-02, 2.20445346e-01,\n",
       "        9.61834359e-03, 2.83505061e-02, 1.88909469e-02, 2.94230729e-02,\n",
       "        7.05017868e-02, 7.57825139e-03, 1.13071374e-01, 1.70695499e-01,\n",
       "        1.50515796e-01, 1.54491321e-02, 5.74362379e-02, 2.09443388e-03,\n",
       "        1.66559319e-02, 4.87925024e-04, 3.20050454e-02, 2.31994568e-03,\n",
       "        1.18606633e-03]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.datasets import make_multilabel_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=5,random_state=0)\n",
    "lda_trained = lda.fit(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 128,\n",
       " 'doc_topic_prior': None,\n",
       " 'evaluate_every': -1,\n",
       " 'learning_decay': 0.7,\n",
       " 'learning_method': 'batch',\n",
       " 'learning_offset': 10.0,\n",
       " 'max_doc_update_iter': 100,\n",
       " 'max_iter': 10,\n",
       " 'mean_change_tol': 0.001,\n",
       " 'n_components': 5,\n",
       " 'n_jobs': None,\n",
       " 'perp_tol': 0.1,\n",
       " 'random_state': 0,\n",
       " 'topic_word_prior': None,\n",
       " 'total_samples': 1000000.0,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.610725168989717"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.bound_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.19987838,  3.19951541, 10.20086394, 11.20026761,  8.19977108,\n",
       "         3.1987176 , 12.20051215, 13.20012646, 11.19947855, 14.20052974],\n",
       "       [15.20005005, 16.20130265,  5.19948615, 17.20038318, 15.20022882,\n",
       "        18.2007039 , 19.20069516, 15.19958194, 20.20000234,  3.19798761],\n",
       "       [ 0.20003501,  0.20005971,  0.20005608,  0.20005431,  0.20005405,\n",
       "         0.20005485,  0.20005521,  0.20005333,  0.20005318,  0.20005451],\n",
       "       [ 0.20000155,  1.19906252,  2.19953775,  3.1992406 ,  4.199892  ,\n",
       "         5.20046879,  2.19868227,  6.20018494,  7.20041274,  8.20137363],\n",
       "       [ 0.20003501,  0.20005971,  0.20005608,  0.20005431,  0.20005405,\n",
       "         0.20005485,  0.20005521,  0.20005333,  0.20005318,  0.20005451]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
